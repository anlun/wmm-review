\section{Analysis}

In this section we present the detailed comparison 
of the considered programming language memory models. 

We summarize our findings in \cref{table:summary}. 
Each row of the table corresponds to a memory model, denoted by its abbreviation. 
The correspondence between the memory model abbrevation, 
its full name and the research papers is given in \cref{table:mmodels}.
Columns of the table correspond to properties of the models. 
We split the properties into several subgroups. 

The first group is devoted to optimality of compilation mappings
to target hardware instructions. In order to be concise, 
we chose the binary classification of optimality, 
that is we classify the compilation scheme as either optimal or not,
in the following sense.
We chose the weakest possible access mode supported by the model
and consider the compilation scheme for the memory accesses annotated by this mode. 
However, for the memory models that treat racy non-atomic accesses
as undefined behavior, we consider the compilation mapping
for relaxed accesses (or stronger, in case when the model does not support relaxed atomics).  
This is because the catch-fire semantics for racy non-atomics 
trivially permits the most optimal compilation mappings (see \cref{sec:bgrnd-ub}).
We say that compilation scheme is optimal if the accesses annotated by the chosen mode 
can be compiled as plain load and store instructions of the given hardware architecture. 

The second group is dedicated to soundness of various program transformations. 
The classification is also binary: a transformation is either sound or unsound 
in the given memory model (in a sense stated in \cref{sec:bgrnd-opt-sound}).
Again, to be concise, we do not consider all the combinations 
of program tranformations and memory access modes. 
Instead, we consider the weakest possible accesses which have fully defined semantics. 
We further split the transformations into global and local as in \cref{sec:bgrnd-opt-sound}.

The third group corresponds to reasoning principles guaranteed by the model. 
It includes the following properties. What kind of DRF guarantee the model provides.
(we distinguish the internal, external and local DRF theorems, see \cref{sec:bgrnd-drf}).
Whether the model has undefined behaviors (see \cref{sec:bgrnd-ub}).
Whether the model permits out-of-thin-air values (see \cref{sec:bgrnd-oota}).

Finally, the last group enumerates the list of memory access modes 
and fences supported by the model, as well as whether the model 
supports read-modify-write operations, locks, and mixed-size accesses.

Driven by our analysis of the models' properties, we partition all models into five classes. 
The models from the same class have similar compilation mappings, 
set of sound program transformations, and provided reasoning guarantees.
Our classes are ordered by the weakness of the memory models they consist of.  
The strongest models are located at the top rows of the table, 
while the weakest are at the bottom. 

We next discuss each class in more details
(note that the order is different from the one in the \cref{table:summary}). 
We also give some insight on the relationship
between compilation scheme optimality, 
soundness of transformations and reasoning guarantees.
In particular, we explain why the support of some reasoning guarantees 
disables some program transformations and requires more heavyweight 
compilation mappings to hardware.

\subsection{Strong SC-like Models}

The sequential consistency is the strongest model one can imagine. 
It renders many common transformations unsound, 
including all kind of instruction reorderings and 
common subexpression elimination~\cite{Marino-el:PLDI11, Sevcik-Aspinall:ECOOP08}.
The fact that instruction reorderings are forbidden 
makes the model expensive to implement on modern hardware
since even the strongest hardware model, namely the x86-TSO,
permits store/load reordering as an optimization.
Therefore, to preserve sequential consistency during compilation,
the compiler need to emit heavyweight full memory fences,
which makes compilation mappings far from optimal.  

In terms of reasoning guarantees, however, SC is quite a pleasant model. 
It gives the DRF-SC and coherence (\eupp{s/coherence/SC-per-location?}) 
properties for free
\footnote{The SC semantics assigns to programs only sequantially consistent
outcomes by definition, thus satisfying DRF-SC without any preconditions.
The coherence property is equivalent to sequential consistency per location.
The fact that in SC model any execution is sequeantially consistent implies trivially
that the accesses to each location are also sequeantially consistent.}
and it is naturally program order preserving.

The conceptual simplicity of SC have inspired many researchers 
to adopt it and to try to mitigate the induced performance 
penalty by some additional measures.

The work by Marino et al~\cite{Marino-el:PLDI11, Singh-el:ISCA12} 
examined the performance penalties to ensure end-to-end SC
enforced by (1) modified SC-preserving version 
of LLVM compiler infrastructure and 
(2) a modified version of x86-TSO hardware. 
To mitigate the induced overhead the authors 
utilized the observation that hardware need to 
enforce SC only for memory accesses to shared mutable variables. 
To classify the memory regions as either thread-local,
shared immutable, or shared mutable they have used 
a combination of static compiler analysis and 
dynamic analysis powered by modified hardware. 
They evaluated their approach on a number of benchmarks
and reported performance overhead of 6.2\% on avarage 
and ~17\% in maximum, compared to stock LLVM compiler 
and regular x86 hardware. 

The SC-Haskell memory model~\cite{Vollmer-el:PPoPP17}
were inspired by the same idea of separation
between the thread-local and shared mutable memory. 
To safely distinguish between the two 
the authors utilized the powerful strong type system of Haskell. 
The consequence of this approach is that the 
programmers need to follow a stricter discipline 
in order to please the type checker. 
The authors modified the GHC to preserve SC 
and then run 1,279 benchmarks on x86-64 hardware
to measure the performance penalties.
They reported 0.4\% geometric mean slowdown,
and noticed that only 12 benchmars expierenced 
slowdown greater than 10\%.

The DRFx~\cite{Marino-el:PLDI10} is another 
SC preserving memory model. In this memory model
the runtime system is guaranteed to raise 
an exception if the program has data-races, 
and yeild only sequantially consistent outcomes otherwise.
In order to make the runtime data-race detection feasible 
in practice, the authors propose several modifications 
to existing hardware.
The authors claim that any sequentially valid optimization 
(\eg instruction reorderings or common subexpression elimination),
is \textbf{sound} in DRFx model.
The only limitation is that these transformations can only be performed
withing the bounds of compiler-designated program regions.
Importantly, any transformation that introduces 
speculative reads or writes is \textbf{unsound},
since speculative optimizations can bring
data-races into otherwise race-free programs.
The expected performance overhead of the model 
is reported to be 3.25\% on average
assuming the efficient implementation 
of data-race detection in hardware. 
(compared to stock compiler and x86 hardware). 

Given the results of performance evaluation above,
one can argue that the cost is worth the prize
of having simple SC-like model.
However, we point out that the two 
of the solutions above~\cite{Singh-el:ISCA12, Marino-el:PLDI10} 
require non-trivial modifications to the 
existing hardware and compilers.
In case of SC-Haskell~\cite{Vollmer-el:PPoPP17}, 
the programmers are obligated to follow 
a strict programming discipline enforced 
by the type system of the language.
In all research papers above the expirements 
of proposed solutions were mainly evaluated on x86 hardware, 
and the impact of enforcing SC on weaker hardware
(ARM, POWER) is less clear. 
Moreover, while the reported performance overhead 
is relatively small on average, 
it is more significant for particular 
kind of programs that heavily utilize shared 
mutable memory (like lock-free data structures).
\eupp{check the evaluation in the papers once again
to support this claim}

\subsection{Strong TSO-like Models}

The next class of PL memory models we consider 
was inspired by TSO~\cite{Sewell-al:CACM10} and PSO~\cite{Sparc:94} 
hardware models. In these models, threads usually 
are equipped with \emph{store buffers}.
All store operations go to these buffers before they 
propogate into the main memory.  
In essence, store buffers enable 
store/load reordering (in case of~TSO),
and store/load \& store/store reordegins (in case of~PSO).

The models based on store buffers idea 
can be compiled down to x86 hardware without any 
perfrormance penalty, since x86 implements TSO model itself.
That is, the compilation mappings to x86 are optimal.
However, when compiled down to weaker hardware (e.g. ARM, POWER)
the compiler indeed needs to take additional measures 
to enforce TSO/PSO like memory model.
\eupp{Perhaps, we can cite some paper here?} 

The TSO/PSO models are weaker than SC, while 
they are still relatively strong.
The external DRF-SC and coherence still hold
and program order is preserved.

We are aware of two papers that propose to use TSO/PSO 
like models as PL level memory models.

Demange et al.~\cite{Demange-el:POPL13} presented 
the \emph{Buffered Memory Model} (or BMM in short)
as a candidate model for Java language.
Their motivation, however, stemmed not from the desire 
to fully replace the Java Memory Model, but rather 
from the goal to build a verified version of 
Java Virtual Machine (akin to CompCertTSO project).
By taking a relatively simple and yet pragmatic memory model
as a first target they hoped to made this task feasible. 
The authors proved soundness of several program transformations
(including store/load reordering, speculative load introduction,
and several others, see 
the \cref{table:summary} for details\footnote{
\eupp{If we'll decide to mention thread inlining w.r.t. TSO
then cite~\cite{Lahav-Vafeiadis:FM16} 
(since the paper itself doesn't mention this transformation)}})
and the external DRF-SC theorem. 
They also modified existing open-source implementation of 
JVM~\cite{Pizlo-el:ECCS10} to preserve BMM and 
reported only~1\% average overhead 
compared to original version of the virtual machine. 
Again, the authors used only x86 hardware in their 
experiments, and the performance penalties 
are expected to be more significant on weaker hardware.   

In~\cite{Boudol-el:POPL09} the authors propose 
an approach to formal semantics of relaxed memory models 
based on the abstract machine with the main memory 
and the hierarchial structure of store buffers 
with stores to different locations possibly 
propagating to the main memory out-of-order
(similarly to PSO model).
The authors present a proof of DRF-SC theorem,
but do not provide an extensive study 
of program transformations' soundness.

\subsection{OOTA Models}

\begin{itemize}
  \item Pros.
  \begin{itemize}
    \item Cheap compilation to hardware.
    \item Almost all transformations are sound. 
  \end{itemize}
  \item Cons.
  \begin{itemize}
    \item No external DRF (only internal).
  \end{itemize}
\end{itemize}

\subsection{$\lPO\cup\lRF$ Acyclic Models}

\begin{itemize}
  \item Pros.
  \begin{itemize}
    \item Many desired transformations are sound. 
    \item Simple solution to forbid OOTA.
  \end{itemize}
  \item Cons.
  \begin{itemize}
    \item Compilation to ARM and POWER is still not optimal.
    \item Load/Store reordering is still unsound.
  \end{itemize}
\end{itemize}

\subsection{$\lPPO\cup\lRF$ Acyclic Models}

\begin{itemize}
  \item Pros.
  \begin{itemize}
    \item (?)
  \end{itemize}
  \item Cons.
  \begin{itemize}
    \item Trace preserving transformations are unsound.
  \end{itemize}
\end{itemize}

\subsection{no-OOTA Models}

\begin{itemize}
  \item Pros.
  \begin{itemize}
    \item Cheap compilation to hardware.
    \item Almost all transformations are sound (including all reorderings). 
  \end{itemize}
  \item Cons.
  \begin{itemize}
    \item Complexity.
    \item No common ground between various models.
    \item It's unknown how to make thread inlining sound (?).
  \end{itemize}
\end{itemize}

\newpage
\onecolumn

\begin{landscape}

\begin{table*}
\begin{tabular}{|c|l|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|}
 \hline

                                                      &
 \multirow{3}{*}{Model}                               & 
 \multicolumn{ 4}{c|}{\multirow{2}{*}{Compilation}}   &
 \multicolumn{10}{c|}{Transformations}                &
 \multicolumn{ 6}{c|}{Reasoning}                      &
 \multicolumn{ 9}{c|}{\multirow{2}{*}{Features}}      \\ 

 \cline{7-22}

                             &
                             &
 \multicolumn{4}{c|}{}       &
 \multicolumn{7}{c|}{Local}  &
 \multicolumn{3}{c|}{Global} &

 \multicolumn{3}{c|}{DRF}    &
 \multicolumn{3}{c|}{}       &
 \multicolumn{9}{c|}{}       \\ 
 
 \hline
                                     &
                                     &
 \rotatebox[origin=c]{270}{x86}      & 
 \rotatebox[origin=c]{270}{Power}    & 
 \rotatebox[origin=c]{270}{ARMv7}    & 
 \rotatebox[origin=c]{270}{ARMv8}    & 
 
 \rotatebox[origin=c]{270}{TP}     &
 \rotatebox[origin=c]{270}{RI}     &
 \rotatebox[origin=c]{270}{RE}     &
 \rotatebox[origin=c]{270}{ILE}    &
 \rotatebox[origin=c]{270}{SLI}    &
 \rotatebox[origin=c]{270}{S}      &
 \rotatebox[origin=c]{270}{RM}     &
 \rotatebox[origin=c]{270}{RP}     &
 \rotatebox[origin=c]{270}{VR}     &
 \rotatebox[origin=c]{270}{TI}     &
 
 \rotatebox[origin=c]{270}{Int}    &
 \rotatebox[origin=c]{270}{Ext}    &
 \rotatebox[origin=c]{270}{Loc}    &

 \rotatebox[origin=c]{270}{UB}                                 &
 \rotatebox[origin=c]{270}{\makecell{$\lPO\cup\lRF$ \\ acyc.}} & 
 \rotatebox[origin=c]{270}{OOTA}                               &                              


 \rotatebox[origin=c]{270}{NA}                      &
 \rotatebox[origin=c]{270}{RLX}                     &
 \rotatebox[origin=c]{270}{RA}                      &
 \rotatebox[origin=c]{270}{SC}                      &
 \rotatebox[origin=c]{270}{F-RA}                    &
 \rotatebox[origin=c]{270}{F-SC}                    &
 \rotatebox[origin=c]{270}{RMW}                     &
 \rotatebox[origin=c]{270}{Lock}                    &
 \rotatebox[origin=c]{270}{\makecell{Mix.Sz.}}      \\ 
 
 \Xhline{2\arrayrulewidth}
 
 \multirow{3}{*}{\rotatebox[origin=c]{270}{\makecell{SeqCst}}}   

 & SC             & & & & & & & & & & & & & & & & & & & & & & & & & & & & & \\ \cline{2-31}
 & SC-Haskell     & & & & & & & & & & & & & & & & & & & & & & & & & & & & & \\ \cline{2-31}
 & DRFx           & & & & & & & & & & & & & & & & & & & & & & & & & & & & & \\ \Xhline{2\arrayrulewidth}

 \multirow{2}{*}{\rotatebox[origin=c]{270}{\makecell{TSO\\PSO}}}   

 & BMM            & & & & & & & & & & & & & & & & & & & & & & & & & & & & & \\ \cline{2-31}

 & Rlx Op.Sem.    & & & & & & & & & & & & & & & & & & & & & & & & & & & & & \\ \Xhline{2\arrayrulewidth}

 \multirow{5}{*}{\rotatebox[origin=c]{270}{\makecell{$\lPO\lRF$\\acyc}}}   

 & RC11           & & & & & & & & & & & & & & & & & & & & & & & & & & & & & \\ \cline{2-31}

 & ORC11          & & & & & & & & & & & & & & & & & & & & & & & & & & & & & \\ \cline{2-31}

 & OCaml MM       & & & & & & & & & & & & & & & & & & & & & & & & & & & & & \\ \cline{2-31}

 & JAM            & & & & & & & & & & & & & & & & & & & & & & & & & & & & & \\ \cline{2-31}

 & Rlx Compos.    & & & & & & & & & & & & & & & & & & & & & & & & & & & & & \\ \Xhline{2\arrayrulewidth}

 \multirow{2}{*}{\rotatebox[origin=c]{270}{\makecell{$\lPPO\lRF$\\acyc}}}   

 & LKMM           & & & & & & & & & & & & & & & & & & & & & & & & & & & & & \\ \cline{2-31}

 & OHMM           & & & & & & & & & & & & & & & & & & & & & & & & & & & & & \\ \Xhline{2\arrayrulewidth}

 \multirow{7}{*}{\rotatebox[origin=c]{270}{\makecell{no-OOTA}}}   

 & JMM            & & & & & & & & & & & & & & & & & & & & & & & & & & & & & \\ \cline{2-31}

 & Promising      & & & & & & & & & & & & & & & & & & & & & & & & & & & & & \\ \cline{2-31}

 & Weakestmo      & & & & & & & & & & & & & & & & & & & & & & & & & & & & & \\ \cline{2-31}

 & MRD            & & & & & & & & & & & & & & & & & & & & & & & & & & & & & \\ \cline{2-31}

 & P-P/S          & & & & & & & & & & & & & & & & & & & & & & & & & & & & & \\ \cline{2-31}

 & J/R            & & & & & & & & & & & & & & & & & & & & & & & & & & & & & \\ \cline{2-31}

 & Generative     & & & & & & & & & & & & & & & & & & & & & & & & & & & & & \\ \Xhline{2\arrayrulewidth}

 \multirow{5}{*}{\rotatebox[origin=c]{270}{\makecell{OOTA}}}   

 & C11            & & & & & & & & & & & & & & & & & & & & & & & & & & & & & \\ \cline{2-31}

 & JS MM          & & & & & & & & & & & & & & & & & & & & & & & & & & & & & \\ \cline{2-31}

 & RMC            & & & & & & & & & & & & & & & & & & & & & & & & & & & & & \\ \cline{2-31}

 & RAO            & & & & & & & & & & & & & & & & & & & & & & & & & & & & & \\ \cline{2-31}

 & Spec.Comp.     & & & & & & & & & & & & & & & & & & & & & & & & & & & & & \\ \Xhline{2\arrayrulewidth}


\end{tabular}
\caption{
  % \textit{T.P.} --- trace preserving.
  % \textit{R.I.} --- reordering of independent instructions.
  % \textit{R.E.} --- redundunt load/store elimination.
  % \textit{I.L.E.} --- irrelevant load elimination.
  % \textit{S.L.I.} --- speculative load introduction.
  % \textit{S.} --- strengthening.
  % \textit{R.M.} --- roach motel reordering.
  % \textit{R.P.} --- register promotion.
  % \textit{V.R.} --- value range analysis based optimizations.
  % \textit{T.I.} --- thread inlining (sequentialization).
  % \textit{Int.} --- internal.
  % \textit{Ext.} --- external.
  % \textit{Loc.} --- local.
  % \textit{UB} --- undefined behavior.
  % \textit{OOTA} --- out-of-thin air values.
  % \textit{Mix.Sz.} --- mixed-size accesses.
}
\label{table:summary}
\end{table*}

\end{landscape}

\twocolumn