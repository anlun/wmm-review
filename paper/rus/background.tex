\section{Criteria for Memory Models}
\label{sec:background}

В этой секции мы более подробно рассмотрим 
критерии для сравнения моделей памяти языков программирования,
в частности оптимальность схем компиляции \ref{item:criteria:opt-comp},
корректность трансформаций \ref{item:criteria:sound-trans}
и предоставляемые гарантии \ref{item:criteria:reasoning}.
Эти критерии непосредственно связаны с примитивами, 
предоставляемыми абстракцией разделяемой памяти. 
Таким образом, сначала нам необходимо ввести эти примитивы. 

\paragraph{Programming Primitives}
\label{sec:background:primitives}

Модель памяти определяет семантику разделяемой памяти
в присутствии конкурентно исполняемых потоков. 
Разделяемая память состоит из индивидуальных переменных, 
каждая из которых имеет уникальный адрес.% 
\footnote{В этой статье мы будем использовать 
термины адрес и локация взаимозаменяемо.}
Потоки могут обращаться к этим переменным, 
выполняя чтения и записи. 

% \begin{figure}[t]
% \[\def\arraystretch{1.2}
%   \begin{array}{ll} 
%     \readInst{o}{r}{x}                  & \text{Load}                   \\ 
%     \writeInst{o}{x}{v}                 & \text{Store}                  \\ 
%     \readArrayInst{o}{r}{x}{i}{j}       & \text{Mixed Size Load}        \\ 
%     \writeArrayInst{o}{x}{v}{i}{j}      & \text{Mixed Size Store}       \\ 
%     \casInst{o}{r}{x}{v_e}{v_d}         & \text{Compare-and-Swap}        \\ 
%     \faddInst{o}{r}{x}{v}               & \text{Fetch-and-Add}          \\ 
%     \lockInst{l}                        & \text{Lock}                   \\ 
%     \unlockInst{l}                      & \text{Unlock}                 \\ 
%     \fenceInst{o}                       & \text{Fence}                  \\ 
%     x \in \mathsf{Var}                  & \text{Shared Variables}       \\ 
%     r \in \mathsf{Reg}                  & \text{Thread-Local Registers} \\ 
%     v \in \mathsf{Val}                  & \text{Values}                 \\ 
%     l \in \mathsf{Lock}                 & \text{Locks}                  \\ 
%     i,j \in \mathsf{Index}              & \text{Array Indices}          \\ 
%     o \in \set{\na,\rlx,\acqrel,\sco}   & \text{Access Modes}           \\ 
%   \end{array}
% \]
% \caption{Primitives of relaxed memory models}
% \label{fig:wmm-abs}
% \end{figure}

Большинство языков программирования различают 
\emph{неатомарные} (также иногда называемые \emph{обычными})
и \emph{атомарные} переменны.
Первые не должны использоваться для конкурентных 
обращений из параллельных потоков. 
В зависимости от конкретного языка программирования,
конкурентные обращения к неатомарным переменным 
либо полностью запрещены системой типов
(\eg \Haskell~\cite{Marlow-al:Haskell10, Vollmer-al:PPoPP17}, \Rust~\cite{RustBook:19}), 
либо имеют неопределенное поведение (\eg \CPP~\cite{Boehm-Adve:PLDI08, Batty-al:POPL11}), 
либо обладают очень слабой семантикой
не дающей практическии никаких гарантий о порядке
в котором конкурентные потоки могут наблюдать эти обращения
(\eg \Java~\cite{Manson-al:POPL05}). 

В свою очередь, атомарные переменные напрямую 
предназначены для конкурентных обращений. 
Некоторые модели памяти также разделяют 
несколько типов обращений к атомарным переменным.
В таким моделях эти обращения аннотируются 
так называемым \emph{режимом доступа} (\emph{access mode}).
Например, язык \CPP (и более новая версия \Java~\cite{Bender-Palsberg:OOPSLA19})
различают три режима: ослабленный \emph{relaxed}
(непрозрачный \emph{opaque} в терминологии \Java),
режим захвата/освобождения \emph{acquire/release} 
и последовательно согласованный \emph{sequentially consistent}
(изменчивый \emph{volatile} в \Java). 
Режимы обозначаются как $\rlx$, $\acq$, $\rel$ и $\sco$ соответственно.
Заметим, что режим $\acq$ может быть применен только к операциям чтения,
а режим $\rel$ только к записям.
Неатомарные обращения иногда рассматриваются как четвертый режим $\na$, 
однако заметим, что одновременное использование атомарных 
и неатомарных обращений к одной и той же переменной 
влечет неопределенное поведение в \CPP.

Режимы обращения упорядочены по гарантиям 
которые они предоставляют, как показано на следущей диаграмме. 

% $$ \na \sqsubseteq \rlx \sqsubseteq \acqrel \sqsubseteq \sco $$

\input{../common/modes.tex}

На одном из концов спектра находятся последовательно согласованные обращения.
При правильном использовании они гарантируют семантику 
последовательной согласованности
(детали этого обсуждаются в разделе \cref{sec:background:drf}).
Неатомарные обращения либо не дают никаких гарантий, 
либо предоставляют минимальные гарантии. 
Ослабленные обащения также имеют слабую семантику, 
тем не менее обычно они предоставляют свойство \emph{когерентности}
(\emph{см.} раздел \cref{sec:background:coh}).
Наконец, в середине находится обращения с режимом захвата/освобождения. 
Они необходимы для поддержи идиомы передачи сообщений~\cite{Lahav-al:POPL16}.
Поток желающий отправить сообщение может выполнить освобождающую запись, 
другой поток ожидающий сообжение должен выполнить захватывающее чтение. 
Если это чтение наблюдает освобождающую запись, 
тогда два потока синхронизируются.

Модель памяти также может предоставлять атоманые операции 
\emph{чтения-модификации-записи} (\emph{read-modify-write}).
Они включают операции сравнения и замены (\emph{compare-and-swap}), 
атомарного обмена (\emph{exchange}), и разные вариации атомарного инкремента, 
\eg \emph{fetch-and-add}, \emph{fetch-and-sub}, \etc 
Операция сравнения и замены (\CAS) принимает на вход 
адрес разделяемой переменной, ожидаемое и желаемое значение.
Она выполняет чтение из переменной и сравнивает полученное значение 
с ожидаемым. Если они равны, то выполяется замена значения переменной 
на желаемое. Также, прочитанное значение возвращается как результат, 
вне зависимости от успеха проверки. 
Заметьте, что описанные выше действия просходят атомарно, 
ни одна другая запись не может произойти между 
чтением и записью операции \CAS.
Операция обмена (\emph{exchange}) атомарно 
заменят значение переменной и возвращает её 
значение до замены. 
Атомарный инкремент (\emph{fetch-and-add} и другие) выполняет
атомарную операцию и возвращает значение переменной до модификации.  

Блокировки (\emph{locks}) иногда рассматриваются 
как часть модели памяти~\cite{Manson-al:POPL05}, 
также как и барьеры (\emph{fence})~\cite{Batty-al:POPL11},
соответствующие инструкциям барьеров памяти 
выполняемых процессорами  
(\emph{см.} раздел \cref{sec:background:compile}). 

Наконец, модель памяти может рассматривать разделяемую память 
не как множество независимых типизированных переменных, 
а как последовательность байт, и допускать 
так называемые \emph{смешанные} (\emph{mixed-size}) 
конкурентные обращения~\cite{Flur-al:POPL17}.. 
Например, в подобной модели чтение 8 байт по определенному адресу
может прочитать значение записанное двумя конкурентными 
записями по 4 байта.

\subsection{Compilation Scheme}
\label{sec:background:compile}

Далле мы рассмотрим первый критерий~\ref{item:criteria:opt-comp}
для сравения моделей памяти языков программирования --- 
оптимальность схемы компиляции. 
\emph{Схема компиляции} --- это отображение
примитивов языка программирования в инструкции 
конкретого семейства процессоров.  
Мы будем рассматривать примитивы представленные в 
разделе \cref{sec:background:primitives}.
Архитектуры процессоров обычно предоставляют 
схожий набор примитивов, который включает 
инструкции для выполнения обычных чтения и записей,%  
\footnote{Некоторые архитектуры
предоставляют дополнительные инструкции чтения и 
записи с режимом доступа, \eg 
\eg \texttt{lda} --- захватывающее чтение (load acquire), 
и \texttt{stl} --- освобождающая запись (store release) в \ARMv{8}.} 
операции чтения-модификации-записи, и 
также различные типы барьеров памяти.

Схема компиляции должна быть корректной. 
В контексте данной статьи мы будем подразумевать под 
этим следующее --- множество поведений допустимых
моделью памяти процессора для скомпилированной программы 
должно являться подмножеством поведений допустимых 
моделью языка программирования для исходной программы. 

Рассмотрим пример. 
Программа \ref{ex:sb} ниже является 
фрагментом \ref{ex:Dekker} из раздела \cref{sec:intro}.

\begin{equation*}
\inarrII{
   \writeInst{}{x}{1}   \\
   \readInst{}{r_1}{y}  \\
}{
  \writeInst{}{y}{1}   \\
  \readInst{}{r_2}{x}  \\
}
\tag{SB}\label{ex:sb}
\end{equation*}

Предположим, что язык программирования предоставляет 
модель последовательной согласованности, а программа
должна быть скомпилирована для процессоров \Intel. 
Если компилировать чтения и записи как обычные 
инструкции чтения и записи \Intel,\footnote{
В архитектуре \Intel инструкция \texttt{MOV} 
используется как для чтений, так и для записи в память.}
тогда результат работы скомпилированной программы
$[r_1=0, r_2=0]$ будет допустим спецификацией модели памяти \Intel
(и может наблюдаться на практике), 
Этот результат может наблюдаться как результат 
\emph{буфферизации записи}
(отсюда и название программы \ref{ex:sb} --- \emph{store buffering}). 
Запись ${\writeInst{}{x}{1}}$ может быть буфферизирована 
и исполнена после всех остальных инструкций программы. 
Тем не менее, результат ${[r_1=0, r_2=0]}$ не является последовательно согласованным. 
Таким образом, рассмотренная схема компиляции не является корректной. 
Как было продемонстрировано в разделе \cref{sec:intro}, 
некорректность схемы компиляции может иметь 
печальные последствия и нарушать корректность программы. 

Корректная схема компиляции для модели последовательной согласованности 
под архитектуру \Intel может компилировать 
запись как инструкцию записи, за которой следует 
инструкция \texttt{mfence}~\cite{Sewell-al:CACM10, Batty-al:POPL11}, 
как продемонстрировано ниже:

\begin{equation*}
\inarrII{
   \writeInst{}{x}{1}   \\
   \mfenceInst          \\
   \readInst{}{r_1}{y}  \\
}{
  \writeInst{}{y}{1}   \\
  \mfenceInst          \\
  \readInst{}{r_2}{x}  \\
}
\tag{SB+MFENCE}\label{ex:sb-mfence}
\end{equation*}

Инструкция \texttt{mfence} это специальный барьер памяти 
архитектуры \Intel, которая выполняет сброс буффера записей в основную память. 
Для программы \ref{ex:sb-mfence} результат $[r_1=0, r_2=0]$
запрещен моделью памяти \Intel. 

Несмотря на то, что модифицированная схема компиляции является корректной, 
она не \emph{оптимальна}~\cite{OptimalCompilationCPP}, 
в том смысле что она использует барьры памяти,
которые обычно влекут замедление программы 
на 10-30\%~\cite{Marino-al:PLDI11, Liu-al:OOPSLA17}
(\emph{см.} раздел \cref{sec:catalog:sc}).
К сожалению, невозможно иметь \emph{корректную и оптимальную} 
схему компиляции модели последовательной согласованности 
под современные процессоры. 
Этот факт делает модель \SC неподходящей 
для высокопроизводительных языков программирования 
и служит одним из стимулов ослабления моделей памяти. 

В рамках этой статьи, при обсуждении 
схем компиляции мы будем рассматривать процессоры семейств
\Intel, \ARMv{7}, \ARMv{8}, и \POWER, 
по двум основным причинам. 
Во-первых, эти архитектуры наиболее 
распространены на сегодняшний день. 
Во-вторых, модели этих процессоров 
всесторонее изучались исследовательским сообществом, 
что привело к созданию строгих 
формальных спецификаций этих моделей~% 
\cite{Sewell-al:CACM10, Sarkar-al:PLDI11, 
Flur-al:POPL16, Pulte-al:POPL18}. 

\subsection{Program Transformations}
\label{sec:background:trans}

Следующий критерий~\ref{item:criteria:sound-trans} ---
корректность трансформаций, то есть правил переписывания 
исходного кода, применяемых в ходе оптимизацирующих проходов компилятора. 

\emph{Корректная} трансформация должна сохранять семантику программы. 
В нашем контексте, как и в случае корректности схемы компиляции,
это означает что множество допустимых поведений 
программы после применения трансформации должно 
быть подмножеством допустимых поведений оригинальной программы.

Возвращаясь к примеру \ref{ex:sb},
предположим вновь модель последовательной согласованности, 
и рассмотрим трансформацию которая переставляет
инструкцию записи после инструкции чтения в левом потоке, 
в предположении что эти две инструкции 
оперируют над различными адресами переменных:

\begin{minipage}{0.45\linewidth}
\begin{equation*}
\inarrII{
   \writeInst{}{x}{1}   \\
   \readInst{}{r_1}{y}  \\
}{
  \writeInst{}{y}{1}   \\
  \readInst{}{r_2}{x}  \\
}
% \tag{SB}\label{ex:sb-src}
\end{equation*}
\end{minipage}\hfill%
\begin{minipage}{0.05\linewidth}
\Large~\\ $\leadsto$
\end{minipage}\hfill%
\begin{minipage}{0.45\linewidth}
\begin{equation*}
\inarrII{
   \readInst{}{r_1}{y}  \\
   \writeInst{}{x}{1}   \\
}{
  \writeInst{}{y}{1}   \\
  \readInst{}{r_2}{x}  \\
}
% \tag{SBtr}\label{ex:sb-tgt}
\end{equation*}
\end{minipage}

Для преобразованной версии программы (справа),
результат $[r_1=0, r_2=0]$ является последовательно согласованным. 
Тем не менее, для оригинальой версии программы (слева) это неверно. 
Следовательно, вышеупомянутая трансформация 
является некорректной для модели \SC. 

Далее мы представим список различных трансформаций
рассматриваемых в исследованиях по моделям памяти, 
с краткими пояснениями по каждой трансформации. 
Заметим, что этот список далеко не полон, 
и не включает многие оптимизации 
выполняемые компиляторами~\cite{Muchnick:ACDI97}.
Например, он не включает оптимизации над циклами,
так как в теории моделей памяти ещё недостаточно 
проработаны темы гарантий прогресса 
(\emph{liveness properties}), 
которые необходимы для формального 
изучения этих трансформаций. 

Трансформации, которые мы рассматриваем, могут быть 
разделены на два подкласса: \emph{локальные} и \emph{глобальные}.
Локальные трансформации выполняют переписывание 
маленького участка кода в пределах одного потока. 
Для выполнения глобальных транформаций 
необходимо рассматривать всю программу 
(или большую часть программы), 
захватывающую несколько потоков.      
 
\subsubsection{Local Transformations}

\paragraph{
Переупорядочивание независимых инструкций
(Reordering of Independent Instructions)
} 

Эта трансформация выполняет перестановку 
двух смежных инструкций, выполняющих обращение к 
различным адресам в памяти. 
В зависимости от конкретной пары обращений разделяют 
четыре класса переупорядочиваний:
чтения/записи, записи/записи,
чтения/чтения и чтения/записи. 
%
\[\def\arraystretch{1.4}\footnotesize
  \begin{array}{cccl} 

      \writeInst{}{x}{v} \seq \readInst{}{r}{y} 
    & \leadsto 
    & \readInst{}{r}{y} \seq \writeInst{}{x}{v}
    & \text{store/load}  \\ 

      \writeInst{}{x}{v} \seq \writeInst{}{y}{u} 
    & \leadsto 
    & \writeInst{}{y}{u} \seq \writeInst{}{x}{v}
    & \text{store/store}  \\ 

      \readInst{}{r}{x} \seq \readInst{}{s}{y} 
    & \leadsto 
    & \readInst{}{s}{y} \seq \readInst{}{r}{x}
    & \text{load/load}  \\ 

      \readInst{}{r}{x} \seq \writeInst{}{y}{v} 
    & \leadsto 
    & \writeInst{}{y}{v} \seq \readInst{}{r}{x}
    & \text{load/store}  \\ 

  \end{array}
\]

\paragraph{
Элиминация избыточного обращения
(Elimination of Redundant Access)
} 

В паре двух смежных обращений к памяти
одно из них может быть удалено 
если его эффект покрывается другим. 
Например, две записи в одну и ту же переменную 
одного и того же значения могут быть заменены 
на одну запись. 
Аналогично переупорядочиваниям, 
выделяют четыре класса элиминаций
представленных ниже. 
%
\[\def\arraystretch{1.4}\footnotesize
  \begin{array}{cccl} 

      \writeInst{}{x}{v} \seq \readInst{}{r}{x} 
    & \leadsto 
    & \writeInst{}{x}{v} \seq \assignInst{r}{v}
    & \text{store/load}  \\ 

      \readInst{}{r}{x} \seq \readInst{}{s}{x} 
    & \leadsto 
    & \readInst{}{r}{x} \seq \assignInst{s}{r}
    & \text{load/load}  \\ 

      \readInst{}{r}{x} \seq \writeInst{}{x}{r} 
    & \leadsto 
    & \readInst{}{r}{x} 
    & \text{load/store}  \\ 

      \writeInst{}{x}{v} \seq \writeInst{}{x}{u} 
    & \leadsto 
    & \writeInst{}{x}{u}
    & \text{store/store}  \\ 

  \end{array}
\]

\paragraph{
Элиминация нерелевантного чтения
(Irrelevant Load Elimination)
}

Эта трансформация удаляет инструкцию чтения, 
если её результат никогда не используется. 

Yet another elimination transformation 
which removes a load instruction if its 
result is never used. 
%
\[\def\arraystretch{1.4}\footnotesize
  \begin{array}{cccl} 

      \readInst{}{r}{x} 
    & \leadsto 
    & \epsInst
    & ~|~ \text{$r$ is never used}  \\ 

  \end{array}
\]

\paragraph{
Введение спекулятивного чтения
(Speculative Load Introduction)
}

Обратная к предыдущей, эта трансформация 
вставляет инструкцию чтения в произвольное место программы.
%
\[\def\arraystretch{1.4}\footnotesize
  \begin{array}{cccl} 

      \epsInst
    & \leadsto 
    & \readInst{}{r}{x} 
    & ~|~ \text{$r$ is never used}  \\ 

  \end{array}
\]

В комбинации с элиминацей чтения/чтения 
эта трансформация может быть использована 
для того чтобы вынести чтение из 
одной из веток условного оператора:
%
\[\def\arraystretch{1.4}\footnotesize
  \begin{array}{ccc} 

      \kw{if} (e)~ \kw{then} \{ \readInst{}{r}{x} \}
    & \leadsto 
    & \readInst{}{s}{x} \seq \kw{if} (e)~ \kw{then} \{ \assignInst{r}{s} \} \\
    & & ~|~ \text{$s$ is never used}  \\ 

  \end{array}
\]

\paragraph{
(Roach Motel Reordering)
}

Этот класс переупорядочиваний позволяет 
вносить инструкции в блоки синхронизации. 
Например, запись может быть передвинута 
за операцию захвата блокировки. 
Интуитивно, такие перестановки могут 
только увеличить синхронизацию в программе, 
то есть преобразованная программа 
должна обладать меньшим недетерминизмом 
и иметь меньшее количество допустимых поведений. 

Неатомарные обращения могут быть передвинуты 
в критическую секцию без дополнительных условий. 
Кроме того, запись может быть перемещена после 
операции захвата блокировки, а чтение 
может быть перемещено до операции освобождения блокировки. 
Схожие правила применяются к переупорядочиваниям вокруг 
захватывающих (\emph{acquire}) и освобождающих (\emph{release}) операций. 
% %
\[\def\arraystretch{1.4}\footnotesize
  \begin{array}{cccl} 

      \readInst{\na}{r}{x} \seq \lockInst{l} 
    & \leadsto 
    & \lockInst{l} \seq \readInst{\na}{r}{x}
    & ~ \\ 

      \writeInst{o}{x}{v} \seq \lockInst{l} 
    & \leadsto 
    & \lockInst{l} \seq \writeInst{o}{x}{v}
    & ~  \\ 

      \unlockInst{l} \seq \writeInst{\na}{x}{v} 
    & \leadsto 
    & \writeInst{\na}{x}{v} \seq \unlockInst{l}
    & ~ \\ 


      \unlockInst{l} \seq \readInst{o}{r}{x} 
    & \leadsto 
    & \readInst{o}{r}{x} \seq \unlockInst{l}
    & ~  \\ 

  \end{array}
\]


\paragraph{
Усиление обращений
(Strengthening)
}

Подобно предыдущей трансформации, 
усиление обращений к памяти 
увеличивает синхронизацию в программе 
путем замены аннотации режима обращения на более строгую.
Например, неатомарное обращение может быть заменено на 
последовательно согласованное: 
%
\[\def\arraystretch{1.4}\footnotesize
  \begin{array}{cccl} 

      \readInst{o}{r}{x} 
    & \leadsto 
    & \readInst{o'}{r}{x}
    & ~|~ o \sqsubset o' \\ 

      \writeInst{o}{x}{v}
    & \leadsto 
    & \writeInst{o'}{x}{v}
    & ~|~ o \sqsubset o'  \\ 

  \end{array}
\]

\paragraph{
Трансформации сохраняющие трассы
(Trace Preserving Transformations)
}

Этот широкий класс трансформаций включает все трансформации, 
которые не изменяют множество трасс потока~\cite{Sevcik-Aspinall:ECOOP08}.
Трассой называется последовательной видимых побочных эффектов,
производимых во время выполнения потока 
(чтения и записи в разделяему память тоже считаются эффектами).
Классический пример подобной трансформации --- 
\emph{распространение констант}%
~\cite{Muchnick:ACDI97, Wegman-Zadeck:TOPLAS91}.
Ниже приведен пример применения данной трансформации: 
%
\[\def\arraystretch{1.4}\footnotesize
  \begin{array}{cccl} 

      \writeInst{}{x}{0 + v} 
    & \leadsto 
    & \writeInst{}{x}{v}
    & \\ 

  \end{array}
\]
  
\paragraph{
Удаление общих подвыражений
(Common Subexpression Elimination)
}

\CSE является ещё одной классической трансформацией~\cite{Muchnick:ACDI97}, 
которая выполняет поиск и удаление идентичных подвыражений.
Пример работы трансформации:
%
\[\def\arraystretch{1.4}\footnotesize
  \begin{array}{cccl} 

      \readInst{}{r_1}{x + y} \seq \readInst{}{r_2}{x + y} 
    & \leadsto 
    & \readInst{}{r_1}{x + y} \seq \readInst{}{r_2}{r_1}
    & \\ 

  \end{array}
\]

\subsubsection{Global Transformations}

\paragraph{
Продвижение регистров
(Register Promotion)
}

Если компилятор может определить, что 
обращения к разделяемой переменной 
происходят только из одного потока,
тогда он может заменить эту переменную на регистр.
%
\[\def\arraystretch{1.4}\footnotesize
  \begin{array}{ccl} 

      \writeInst{}{x}{v} \seq \readInst{}{r}{x} 
    & \leadsto 
    & \assignInst{s}{v} \seq \assignInst{r}{s}
    \\ 
    
    & & |~ \text{\texttt{x} is not accessed from other threads} \\
    & & |~ \text{\texttt{s} is a fresh register} \\ 

  \end{array}
\]

\paragraph{Слияние потоков (Thread Inlining)}

Трансформация объединяющая два потока в один.
Оказывается что эта, на первый взгляд безобидная,
трансформация не является корректной во многих моделях памяти. 
%
\[\def\arraystretch{1.4}\footnotesize
  \begin{array}{cccl} 

      P \pll Q 
    & \leadsto 
    & P ~\seq Q
    & ~ \\ 
    
  \end{array}
\]


\paragraph{
Трансформации основанные на анализе диапозона значений
(Value Range Based Transformations)
}

Трансформации этого класса могут быть применены
если программа удовлетворяет некоторому инварианту,
выведенному с помощью глобального анализа 
диапазона возможных значений переменной.
Например, в программе ниже условный оператор
может быть удален, так как статический 
анализ может вывести инвариант 
$\mathsf{x} \geq \mathsf{0}$.

{\footnotesize
\begin{minipage}{0.45\linewidth}
\begin{equation*}
\inarrII{
   \readInst{}{r_1}{x}             \\
   \kw{if} (r_1 \geq 0) ~\kw{then} \\
   \quad\writeInst{}{y}{1}         \\
}{
  \readInst{}{r_2}{x}               \\
  \writeInst{}{y}{r_2}              \\
}
\end{equation*}
\end{minipage}\hfill%
\begin{minipage}{0.05\linewidth}
\Large~\\ $\leadsto$
\end{minipage}\hfill%
\begin{minipage}{0.4\linewidth}
\begin{equation*}
\inarrII{
   \readInst{}{r_1}{x}             \\
   \writeInst{}{y}{1}              \\
}{
  \readInst{}{r_2}{x}               \\
  \writeInst{}{y}{r_2}              \\
}
\end{equation*}
\end{minipage}
}

\subsection{Гарантии}

Далее мы обсуждаем третий критерий~\ref{item:criteria:reasoning} ---
гарантии о поведении программ, предоставляемые моделью памяти.

\subsubsection{\DRF теоремы}
\label{sec:background:drf}

При рассуждении о конкурентном коде 
большинство программистов подразумевают 
модель последовательной согласованности. 
Действительно, было бы неправильно ожидать
от них знания всех деталей слабых моделей, 
так как это только усложнило бы и без того 
тяжелую задачу доказательства корректности 
конкурентных программ. 
Свойство \emph{свободы от гонок}
(\emph{data-race freedom})~\cite{Manson-al:POPL05}, 
или кратко \DRF, призваны решить эту диллему. 
Это свойство гарантирует, что правильно 
синхронизированные программы будут иметь 
только последовательно согласованные поведения 
в слабой модели памяти. 
Другими словами, эта гарантия позволяет программистам 
подразумевать модель последовательной согласованности
если они правильно используют примитивы синхронизации. 

Рассмотрим пример. 
Вернемся к программе \ref{ex:sb} из \cref{sec:background:compile}.
Как было продемонстрировано, в слабой модели 
эта программа может допускать результат ${[r_1=0, r_2=0]}$.
Тем не менее, семантика последовательной согласованности
может быть восстановлена, например при помощи блокировок, 
как показано в примере ниже:

\begin{equation*}
\inarrII{
   \lockInst{l}         \\
   \writeInst{}{x}{1}   \\
   \readInst{}{r_1}{y}  \\
   \unlockInst{l}       \\
}{
   \lockInst{l}         \\
   \writeInst{}{y}{1}   \\
   \readInst{}{r_2}{x}  \\
   \unlockInst{l}       \\
}
\tag{SB+LOCK}\label{ex:sb-lock}
\end{equation*}

Совместимая с \DRF слабая модель памяти должна гарантировать, 
что для программы выше допустимы только 
последовательно согласованные поведения:
${[r_1=0, r_2=1]}$, ${[r_1=1,r_2=0]}$, или ${[r_1=1,r_2=1]}$.

Если модель предоставляет последовательно согласованный 
режим доступа, тогда программист также может 
аннотировать все обращения как последовательно согласованные:
 
\begin{equation*}
\inarrII{
   \writeInst{\sco}{x}{1}   \\
   \readInst{\sco}{r_1}{y}  \\
}{
   \writeInst{\sco}{y}{1}   \\
   \readInst{\sco}{r_2}{x}  \\
}
\tag{SB+SC}\label{ex:sb-sc}
\end{equation*}

Более формально, \DRF теорема для слабой модели $М$
утверждает, что если программа не содержит гонок в модели 
последовательной согласованности, тогда в модель $M$
допускает только последовательно согласованные поведения.

Свойство \DRF позволяет свести рассуждения о поведении программы 
в слабой модели к рассуждениям в модели последовательной согласованности.
Достаточно лишь показать, что программа не имеет гонок 
в модели \SC, чтобы вывести что она будет иметь только \SC поведения 
в слабой модели. 

Свойство \DRF в формулировке выше иногда также называется
\emph{внешней свободой от гонок} (\eDRF), 
чтобы отличать её от \emph{внутренней свободы от гонок} (\iDRF).
Последняя гарантирует для программы семантику \SC
в слабой модели $M$ только если программа 
не имеет гонок в \textbf{самой модели $M$}.
Это свойство предоставляет более слабую гарантию
по сравнению с внешней свободой от гонок. 
Оно не позволяет полностью избежать рассуждений 
в терминах слабой модели, так как 
сначала необходимо показать что программа не имеет 
гонок именно в слабой модели. 
Как будет продемонстрировано далее (\emph{см.} \cref{sec:analysis:oota}), 
внутреняя свобода от гонок является компромиссной гарантией 
для определенного класса моделей, которые не могут 
гарантировать внешнюю свободу от гонок. 

\subsubsection{Coherence}
\label{sec:background:coh}

As we demonstrated, memory models of 
modern hardware architectures do not 
provide the sequentially consistent semantics.
Yet they usually provide a weaker property 
called \emph{sequential consistency per location},
also known as \emph{coherence}~\cite{Alglave-al:TOPLAS14}.
Following hardware models many programming language level
memory models also provide this property. 

The coherence property ensures that 
all stores to each particular location 
can be totally ordered and that the 
resulting order, the \emph{coherence order}, reflects 
the order in which stores propagate from threads
into the main memory. 
In particular, coherence implies that  
programs consisting only of accesses to 
a single memory location have 
the sequentially consistent semantics.
For example, consider the following program:

\begin{equation*}
\inarrII{
   \writeInst{}{x}{1}   \\
   \readInst{}{r_1}{x}  \\
}{
   \writeInst{}{x}{2}   \\
   \readInst{}{r_2}{x}  \\
}
\tag{COH}\label{ex:coh}
\end{equation*}

The coherence prescribes to a memory model 
assign to this program only the 
sequentially consistent outcomes: 
${[r_1=1, r_2=2]}$, ${[r_1=1, r_2=1]}$, or ${[r_1=2, r_2=2]}$.
A non-coherent model additionally may permit 
the following outcome ${[r_1=2, r_2=1]}$.
For example, the \Java memory model actually 
allows this outcome~\cite{Manson-al:POPL05}.

\subsubsection{Undefined Behavior}
\label{sec:background:ub}

As we already briefly mentioned, some memory models, 
\eg \CPP, treat racy programs as having 
\emph{undefined behavior}~\cite{Boehm-Adve:PLDI08}
if with at least one of the accesses participating 
in a race is a non-atomic access. 
In other words, for these programs any outcome is possible. 
This property is also sometimes called the \emph{catch-fire semantics}.
  
The practical payoff of this approach  
is that it enables the optimal compilation scheme 
for non-atomic accesses and makes any sequentially valid 
transformation applicable to them.  
Indeed, effects of hardware and compiler 
optimizationz can only be observed due to racy accesses
from concurrent threads. If such accesses are said 
to imply undefined behavior and give no guarantee, 
effects of these optimizations become indistinguishable.

\subsubsection{Speculative Execution and Out~of~Thin-Air~Values}
\label{sec:background:oota}

In order to introduce the last two properties, we turn to an example: 

\begin{equation*}
\inarrII{
  \readInst{}{r_1}{x}     \\
  \writeInst{}{y}{1}      \\
}{
  \readInst{}{r_2}{y}     \\
  \writeInst{}{x}{r_2}    \\
}
\tag{LB}\label{ex:lb}
\end{equation*}

Assume a weak memory model admitting 
the outcome ${[r_1=1, r_2=1]}$ for this program.
For example, hardware memory models of 
\ARMv{7}, \ARMv{8}, and \POWER
allow this outcome, and it can even be 
actually observed on some \ARMv{7} 
machines~\cite{Maranget-al:Tutorial2012}.

The outcome ${[r_1=1, r_2=1]}$ cannot be obtained by some 
\emph{in-order} execution of the program. 
To enable this kind of behaviors for programs, 
a memory model has to utilize some form of 
\emph{speculative execution}~\cite{Boudol-Petri:ESOP10, Boehm-Demsky:MSPC14}.
That is, during the execution, the load $\readInst{}{r_1}{x}$
needs to be buffered and the store $\writeInst{}{y}{1}$ 
needs to be executed out of order
(hence the name of the program LB --- \emph{load buffering}).

However, unrestricted speculations can lead to disruptive results. 
A store executed out of order can turn into 
a self-satisfying prophecy~\cite{Boehm-Demsky:MSPC14}.
Consider the following variation of the load buffering program. 

\begin{equation*}
\small
\inarrII{
  \readInst{}{r_1}{x}   \\
  \writeInst{}{y}{r_1}  \\
}{
  \readInst{}{r_2}{y}   \\
  \writeInst{}{x}{r_2}  \\
}
\tag{LB+data}\label{ex:lb+data}
\end{equation*}

Here, a hypothetical abstract machine can speculate 
to perform a store of value \texttt{1} into the variable \texttt{y}
from the left thread, then read this value in the right thread, 
write it to the variable \texttt{x} and then read it back in the
left thread closing the paradoxical causality cycle.
The value \texttt{1} in the example above appears \emph{out of thin-air}
and then justifies itself leading to the confusing outcome ${[r_1=1, r_2=1]}$.

As we will see in \cref{sec:analysis}, speculative execution 
is required to enable certain program transformations. 
However, speculations should be properly constrained
in order to prevent an appearance of thin-air values. 
In \cref{sec:analysis:porf,sec:analysis:deprf,sec:analysis:sdeprf}
we will see how various memory models deal with this problem. 
