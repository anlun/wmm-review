\section{Catalog of Memory Models}
\label{sec:catalog}

В этом приложении мы погружаемся внутрь классов 
моеделей памяти, представленных в~\cref{sec:analysis},
и представляем более детальный взгляд на каждую модель памяти.
Этот раздел содержит краткий обзор каждой отдельной модели памяти, 
резюме её особенностей и свойств, а также ссылки на работы, 
посвященные этой модели.   
 
\subsection{Sequential Consistency}
\label{sec:catalog:sc}

Мы начинаем с разбора нескольких попыток 
адаптации модели последовательной согласованности 
в качестве модели памяти существующих языков программирования. 
Так как большинство предложенных решений имеют 
схожие свойства, в таблице \cref{table:cmp-mms} 
мы объединили их в одну строку с именем \SC. 
Исключением является только модель \DRFx,
которая реализует возгорающуюся семантику 
и таким образом несколько отличается от других моделей в данном классе. 

\paragraph{End-to-end Sequential Consistency}

В работах~\cite{Marino-al:PLDI11, Singh-al:ISCA12} 
изучались накладные расходы, необходимые для того, 
чтобы гарантировать модель последовательной согласованности, 
путем (1) модификации инфраструктуры компилятора \LLVM и 
(2) модификации процессоров семейства \Intel.
Чтобы уменьшить накладные расходы, вызванные строгой моделью памяти, 
авторы использовали наблюдение о том, что 
процессору необходимо гарантировать семантику \SC 
только для обращений к разделяемым изменяемым переменным. 
Чтобы классифицировать регионы памяти как 
локальные для одного потока, разделяемые неизменяемые 
и разделяемые изменяемые, авторы использовали 
комбинацию из статического анализа, выполняемого компилятором, 
и динамического анализа, полагающегося на аппаратную поддержку, 
реализованную в модифицированной версии процессора \Intel. 
Эксперименты показали, что в результате программы 
работают медленее на 6.2\% в среднем и ~17\% максимум, 
по сравнению с немодифицированной версией \LLVM
и оригинальной версией процессора \Intel.

\paragraph{Volatile-by-default}

В работах~\cite{Liu-al:OOPSLA17, Liu-al:PLDI19} изучалась 
модель последовательной согласованности в контексте языка \Java.
Авторы предложили так называемую \emph{volatile-by-default} семантику (\VbD),
которая по умолчанию рассматривает каждое обращение к памяти 
как изменяемое (\emph{volatile}), то есть как последовательно согласованное.  
Эксперименты показали, что этот подход ведет к значительному 
замедлению времени работы программ: 
при исполнении на процессорах семейства \Intel наблюдается 
замедление на 28\% в среднем и на 81\% максимум, 
а на процессорах семейства \ARMv{8}
на 57\% в среднем и на 157\% максимум. 
Авторы попробовали уменьшить накладные расходы и 
предложили новую технику оптимизации для обеспечения модели памяти \SC, 
совместимую с ``компиляцией на лету'' (\emph{just-in-time compilation}).
Они предложили спекулятивно рассматривать каждый объект 
как локальный для потока и компилировать все обращения 
к нему без использования барьеров памяти. 
Если далее в ходе исполнения программы виртуальная машина
обнаруживает обращения к этому объекту из других потоков, 
код доступа к этому объекту перекомпилируется, 
чтобы вставить необходимые барьеры памяти. 
Были проведены замеры времени работы программ
при исполнении на модифицированной версии \JVM,
которая реализует эту оптимизацию. 
В результате наблюдалось меньшее замедление времени работы программ, 
состовляющее 37\% в среднем и 73\% максимум на 
процессорах семейства \ARMv{8}.

\paragraph{SC-Haskell}

Модель памяти \SCHs~\cite{Vollmer-al:PPoPP17}
была вдохновлена схожими идеями, 
заключающимися в разделении локальной для потоков 
и разделяемой изменяемой памяти. 
Чтобы различать два типа памяти, 
авторы использовали систему типов языка \Haskell.
Вследствие этого разработчикам необходимо 
придерживаться более строгой дисциплины программирования, 
чтобы удовлетворить ограничения, накладываемые системой типов. 
Авторы модифицировали компилятор GHC чтобы 
гарантировать модель \SC, и затем 
замерили время работы 1,279 тестовых программ 
при исполнении на процессорах семейства \Intel. 
Согласно их данным, геометрическое среднее 
замедления времени работы составило 0.4\%, 
более того, только на 12 тестах 
наблюдалось замедление более чем на 10\%.
Эти многообещающие результаты частично объясняются тем 
фактом, что язык \Haskell поощрает 
использование функционального стиля программирования, 
который стремится минимизировать использование 
разделяемой изменяемой памяти. 

\paragraph{DRFx}

Модель \DRFx~\cite{Marino-al:PLDI10, Marino-al:TOPLAS2016} --- 
это ещё одна модель, гарантирующая семантику \SC.
В рамках данной модели гарантируется, что 
при обнаружении гонки система времени исполнения языка
генерирует исключение, а в случае отсутствия гонок 
гарантируется что сценарий исполнения программы будет последовательно согласованным.
Чтобы обеспечить работоспособность данной идеи на практике,
авторы предложили несколько модификаций для процессоров, 
обеспечивающих аппаратную поддержку обнаружения гонок.   

Авторы статьи утверждают, что любые трансформации, 
корректные для случая однопоточных программ, 
остаются корректными в модели \DRFx
(включая переупорядочивание инструкций и удаление общах подвыражений).
Единственное ограничение заключается в том, что 
это трансформации разрешено применять только 
внутри границ обозначенных компилятором регионов кода. 
Кроме того, любые трансформации, которые спекулятивно
добавляют операции чтения или записи, 
не являются корректными, 
так как они могут внести гонки в программы, 
которые ранее не содержали гонок.  

Отметим, что несмотря на заверения авторов о корректности широкого набора трансформаций, 
в \cref{table:cmp-mms} мы не помечаем многие из этих трансформаций как корректные, 
из-за соглашения, описаного в \cref{sec:comparison}.
Мы считаем трансформации корректными, только если 
они корректны в семантике, которая не трактует 
гонки как неопределенное поведение. 
Модель \DRFx не удовлетворяет этому требованию, 
так как в этой модели наличие гонки приводит 
к выбрасыванию исключения. 

При условии эффективной реализации 
аппаратного механизма обнаружения гонок в процессоре, 
ожидаемые накладные расходы на время работы программ 
для этой модели памяти состовляют 3.25\% в среднем
в сравнению с компиляцией немодифицированной версией компилятора
и исполнении на немодифицированной версии процессора \Intel.

\subsection{Total and Partial Store Order}

В этом разделе мы обсуждаем модели памяти 
разработанные на основе моделей \TSO и \PSO.

\paragraph{Buffered Memory Model}

В работе была предложена \emph{модель памяти с буфферизацией}
(\emph{Buffered Memory Model}, кратко \BMM), 
как модель памяти для языка \Java. 
Стоит отметить, что авторы не ставили перед собой задачи
полностью заменить модели памяти \Java, 
их целью была разработка верифицированной 
версии виртуальной машины \Java
(по аналогии с проектом CompCertTSO~\cite{Sevcik-al:JACM13} для языка C). 
Более простая, но тем не менее прагматичная модель, 
вдохнвленная моделью \TSO, рассматривалась 
как первый шаг на пути к этой цели. 

Авторы модели доказали корректность нескольких трансформаций
(включая переупорядочивание типа запись/чтение, 
спекулятивное введение чтения, и некоторых других, 
\see \cref{table:cmp-mms}), 
а также выполение свойства внешней свободы от гонок (\eDRF).
Также ими была модифицирована существующая реализация 
\JVM~\cite{Pizlo-al:ECCS10} и добавлена поддеркжа модели \BMM. 
Авторы сообщили о том, что в среднем замедление времени работы 
программ на модифицированной версии \JVM состовляет только~1\% в среднем. 
Следует отметить, что авторы выполняли замери времени исполнения 
только на процессорах семейства \Intel, 
следует ожидать, что замедление будет более существенным 
на процессорах с более слабой моделью памяти. 

\paragraph{Relaxed Memory Models: an Operational Approach}

В работе~\cite{Boudol-Petri:POPL09} был предложен 
операционный подход к заданию формальной семантики 
слабых моделей памяти (\RMMOA), 
основанный на абстрактной машине с общей памятью 
и иерархической структурой буферов для операций записи.
Более того, предложенная модель допускает
переупорядочивание находящихся в одном буфере
операций записи в различные локации памяти
(как в модели \PSO).
Авторы предоставили доказательство того,
что модель предоставляет свойство внешней свободы от гонок (\eDRF), 
но не проводили детального исследования 
корректности различных трансформаций кода. 

\subsection{Program Order Preserving}
\label{sec:catalog:porf}

In this section we describe the memory models 
that preserve program order and forbid any 
kind of speculative executions to tackle 
the problem of thin-air values. 
In particular, we consider \RCMM and 
several derivatives of this model, 
as well as the memory model of \OCaml, 
and the proposed revised model of \Java.  

\paragraph{RC11}

Lahav~\etal~\cite{Lahav-al:PLDI17} formalized 
a version of the \CMM that preserves order between load/store pairs, 
and also repairs the semantics of sequentially-consistent accesses.

The authors proved soundness of several program transformations 
(see \cref{table:cmp-mms} for details). 
Among the unsound transformation, 
the load/store reordering is forbidden for an obvious reasons, 
the speculative load introduction is not supported 
because of the catch-fire semantics for racy programs, 
the \CSE is not supported because relaxed accesses 
enforce coherence (non-atomic accesses 
support this transformation, but their usage entails 
undefined behavior in the presence of races).

The compilation mapping to \Intel is not affected and remain optimal.
One of the possible compilation mappings 
to the \ARM and \POWER architectures 
requires to compile a relaxed load as  
a plain load followed by a spurious conditional branch.
Ou and Demsky~\cite{Ou-Demsky:OOPSLA18} have studied 
the performance penalty of this mapping on \ARMv{8} hardware.
They modified the \LLVM compiler framework 
to enforce the \RCMM memory model
by (1) adjusting the compiler optimization passes and 
(2) changing the compilation mappings.
Several compilation schemes were considered,
among them the one that uses a spurious conditional branch
as described above has demonstrated the most promising results.  
The authors measured the running time on a set of benchmarks 
implementing concurrent data-structures
(\eg locks, stacks, queues, deques, maps
from various open source libraries~\cite{CDSLib, FollyLib, JunctionLib})
and reported an overhead of 0\% on average and 6.3\% in maximum,
compared to the unmodified version of the compiler. 

\paragraph{RAR}

Doherty~\etal~\cite{Doherty-al:PPoPP19} developed an 
operational version of the \RCMM supporting 
release-acquire and relaxed accesses (\RAR). 
On top of it they built proof calculus for 
invariant-based reasoning and verified 
correctness of mutual exclusion algorithms. 

\paragraph{Operational RC11}

Dang~\etal~\cite{Dang-al:POPL19} developed yet another 
operational version of the \RCMM which they called \ORCMM. 
Their motivation was to then develop a 
new program logic and show it's soundness
with respect to the \ORCMM memory model. 
The program logic itself was utilized to 
prove correctness of several synchronization primitives 
from the standard library of the \Rust~\cite{RustBook:19}.

\paragraph{Compositional Relaxed Concurrency}

Dodds~\etal~\cite{Dodds-al:ESOP18} proposed the  
compositional relaxed concurrency semantics (\CRC) 
for the fragment of the \CMM memory model, 
including non-atomic accesses with catch-fire semantics, 
release-acquire accesses, and sequentially-consistent fences. 
Based on this semantics the authors developed 
a tool for automatic verification of program transformations
in the considered fragment of the \CMM model. 
Since the relaxed fragment was not included, 
the authors avoided problems with thin-air values. 

\paragraph{OCaml Memory Model}

Dolan~\etal~\cite{Dolan-al:PLDI18} developed a new 
memory model for the \MOCaml project. 
An important divergence of the \OCaml memory model (\OCMM)
from the \CMM-like models is that the former 
has a weaker notion of the coherence.
The choice of the weaker coherence was deliberate 
with the purpose to enable the common subexpression elimination
(see \cref{sec:analysis:coh} for details).

The authors also were the first to propose the local \DRF property (\lDRF),
a strengthening of the external \DRF (\eDRF). 
While the latter requires an absence of data-races 
for a whole program as a prerequisite, 
the former bounds the effect of races 
to a portion of the program, thus 
enabling the compositional reasoning 
about the behavior of the program. 
The authors discovered that the \lDRF property 
is not compatible with the load/store reordering.
This fact forced them to forbid this transformation
and adapt similar compilation scheme as for \RCMM. 

\paragraph{Java Access Modes}

Bender and Palsberg~\cite{Bender-Palsberg:OOPSLA19} formalized a new revision 
of the Java Memory Model~\cite{JDK9-VarHandle, JEP:193, JDK9-Modes}, 
which was developed to overcome 
the difficulties of the previous one~\cite{Manson-al:POPL05}
(see \ref{sec:catalog:jmm} for details).
The new version of the model was inspired by the \RCMM. 
It introduced a system of annotations on memory accesses, 
called ``Java Access Modes'' (hence the name of the model --- \JAM),
similar to those present in the \CMM like models.
The new model adopted the \RCMM solution to OOTA problem. 
It forbids load/store reorderings on the level of 
opaque (an analog of \CPP relaxed) or stronger accesses.
The model does not tackle the problem of 
thin-air values on the level of plain (\ie non-atomic) accesses.

\subsection{Syntactic Dependencies Preserving}
\label{sec:catalog:deprf}

Next we discuss the programming language memory models 
that track syntactic dependencies.

\paragraph{Linux Kernel Memory Model}

\LKMM~\cite{Alglave-al:ASPLOS18} has adopted 
the idea to track syntactic dependencies in order to 
forbid thin-air values. Despite this choice 
limits the list of supported trace preserving transformations,
in the context of the OS kernel development 
it can be justified by the following arguments. 
First, the Linux kernel targets 
a wide range of hardware architectures with a diverse
set of memory models. To simplify the reasoning about the code, 
it is reasonable to pick a syntactic dependency preserving
model which is conceptually close to those of hardware. 
Second, kernel developers already utilize 
various techniques to prevent certain compiler optimizations%
\cite{Alglave-al:ASPLOS18, LK-MemBarriers, LK-RCU-Deref}.

The authors of the model have empirically tested 
soundness of compilation mappings to 
\Intel, \ARMv{7}, \ARMv{8}, and \POWER hardware. 
They also formalized the read-copy-update 
synchronization mechanism (RCU)~\cite{McKenney-RCU2007} 
extensively used in the Linux kernel development, 
and proved soundness of its implementation with respect to their model.

\paragraph{Operational Happens-Before Model}

In attempt to repair the Java Memory Model (see \cref{sec:catalog:jmm})
Zhang and Feng have proposed the 
operational happens-before model \OHMM~\cite{Zhang-Feng:FCS16}.
Their abstract machine consists of a global event buffer,
where events might be reordered before they propagate into  
a global history based memory, and a replay mechanism 
used to simulate speculative executions. 
To avoid thin-air outcomes the model tracks syntactic dependencies 
between events and forbids the reordering of dependent events. 
The authors proved the external \DRF and 
the soundness of several program transformations
(see \cref{table:cmp-mms}). 

\paragraph{Dependency Preserving Compiler}

Ou and Demsky~\cite{Ou-Demsky:OOPSLA18} studied 
the performance penalty induced by dependency preserving compiler. 
Again, they modified the \LLVM compiler infrastructure 
and run benchmarks from \SPECCPU suite on \ARMv{8} hardware. 
They have observed 3.1\% overhead on average and 17.6\% in maximum. 

\subsection{Semantic Dependencies Preserving}
\label{sec:catalog:sdeprf}

Next we discuss the memory models 
which try to tackle the thin-air values problem 
by developing a notion of semantic dependencies. 
In particular, this class includes the original Java Memory Model, 
the Promising semantics, and several models based 
on the \emph{event structures}~\cite{Winskel:86}.

\paragraph{Java Memory Model}
\label{sec:catalog:jmm}

The original version of the Java memory model \JMM~\cite{Manson-al:POPL05}
was a pioneering work in the area of programming language memory models. 
In order to forbid thin-air outcomes, the memory model used 
a notion of \emph{commit sequence}, \ie a sequence of partial execution graphs.
The model was shown to adhere the external \DRF~\cite{Huisman-Petri:CONCUR07}.
However, the model failed to justify some program transformations 
which were expected to be sound~\cite{Sevcik-Aspinall:ECOOP08} 
(\eg redundant load after load elimination, roach motel reordering, and others,
see \cref{table:cmp-mms} for details). 

\paragraph{Generative operational semantics}

Jagadeesan~\etal~\cite{Jagadeesan-al:ESOP10} attempted to fix \JMM 
and proposed the generative operational semantics 
with speculative execution (\GOS).
To avoid thin-air values they have put stratification constraints 
on speculations. The authors prove the external \DRF theorem. 
Also they verified a few program transformations 
(store/store reordering, load/load elimination, and roach motel reordering), 
but overall their study of transformations was not systematic.  

\paragraph{Promising Semantics}

Kang~\etal~\cite{Kang-al:POPL17, Lee-al:PLDI20} developed 
the Promising semantics (\PRM).
It is the most complete to this day model of the class of
semantic dependency preserving models. 
Its key ingredient is a promising and certification machinery.
During an execution, the abstract machine can 
non-deterministically \emph{promise} to perform some store,
it then has to \emph{certify} the promise is feasible. 
The certification mechanism is defined in the way to forbid thin-air values to appear.
The authors of the model have proven formally 
that \Promising semantics admits many local and global program transformations,
with a notable exception of the thread inlining
(see \cref{table:cmp-mms} for details).

Podkopaev~\etal~\cite{Podkopaev-al:ECOOP17, Podkopaev-al:POPL19} 
proved formally the soundness of standard optimal 
compilation mappings to \Intel, \ARMv{7}, \ARMv{8}, and \POWER.

The model has a fully defined semantics for plain accesses.  
Plain and relaxed accesses, however, have different semantics.
In particular, coherence is enforced only for relaxed accesses. 
This design choice, in particular, allows to support 
\CSE on the level of plain accesses. 

One of a few limitations of the \Promising semantics is that 
it does not support sequentially consistent accesses. 

\paragraph{Weakestmo}

Chakraborty and Vafeiadis~\cite{Chakraborty-Vafeiadis:CGO17, Chakraborty-Vafeiadis:POPL19}
developed a memory model based on the event structures (\WMO). 
They utilize the event structures' capability to simultaneously encode 
multiple conflicting executions in order to model speculative executions.
The model was shown to admit optimal compilation mappings~\cite{Moiseenko-al:ECOOP20},
several program transformation, and the external \DRF.
Unlike \Promising semantics, it also supports 
sequentially consistent accesses.

\paragraph{A Concurrency Semantics for Relaxed Atomics}

Pichon-Pharabod and Sewell~\cite{PichonPharabod-Sewell:POPL16} 
presented the operational memory model (\CSRA) consisting of 
a memory subsystem inspired by the \POWER model 
and a thread subsystem, 
where each thread is represented as an event structure. 
At each step the abstract machine is allowed to either 
commit an event to the storage, or perform a transformation 
on one of the event structures. 
The authors have shown soundness of 
optimal compilation mappings to \Intel and \POWER, 
as well as soundness of several program transformations.
It was later revealed though that the compilation scheme
to \ARMv{7} and \ARMv{8} is not optimal~\cite{PichonPharabod:PhD18}.

\paragraph{Well-Justified Event Structures}

Jeffrey and Riely~\cite{Jeffrey-Riely:LICS16} proposed 
the memory model (\WJES) based on event structures and a notion of 
\emph{well-justification} of events inspired by the game semantics. 
Well-justification is used to prevent thin-air values 
and prove the external \DRF. The authors do not study 
the soundness of program transformations in their model. 
They show, however, a counterexample demonstrating that 
the load/load reordering is unsound. 
This fact also implies that 
the compilation mappings to \ARMv{7}, \ARMv{8}, and \POWER 
are not optimal.   

\paragraph{Modular Relaxed Dependencies}

Paviotti~\etal~\cite{Paviotti-al:ESOP20} constructed the 
denotational semantics based on the event structures (\MRD). 
They employ the event structures to capture 
semantic dependencies between memory access events, 
which are in turn used to rule out thin-air outcomes.
The authors prove the external \DRF and 
the soundness of optimal compilation mappings,
also they present a refinement relation which 
can be used to reason about validity of program transformations. 
However, they have not studied soundness of particular transformations. 

\subsection{Out of Thin-Air Values}

Finally, we discuss memory models admitting thin-air values. 

\paragraph{C11}

The most notable member of the OOTA class is the \CMM model~\cite{Batty-al:POPL11}.
The main purpose of the \CMM model was to adhere to the fundamental principle of \CPP, 
\ie to provide so-called zero-cost abstraction. 
In other words, the memory model was meant to provide 
efficient compilation mappings and support as many transformation as possible.
It was later revealed that the formal model partially fails to achive these goals.

Vafeiadis~\etal~\cite{Vafeiadis-al:POPL15} showed that several program transformation 
(load/store elimination, strengthening, roach motel reorderings, sequentialization) 
that deemed to be correct are actually unsound according to the formal model.
They proposed several local fixes to the model which 
partly repair soundness of transformations and improve 
its meta-theoretical properties. 

Batty~\etal~\cite{Batty-al:ESOP15} showed that 
the model also fails to provide the external \DRF guarantee, 
and that it is ultimately not possible to provide this guarantee
at all within the style of the \CMM formal semantics.
Only the internal \DRF can be proved for it. 

A lot of work~\cite{Batty-al:POPL11, Sarkar-al:PLDI12, Batty-al:POPL12, Batty-al:POPL16} 
was dedicated to prove soundness of optimal compilation mappings 
with respect to formal models of hardware, 
and there the results were mostly positive.
Besides that, Flur~\etal~\cite{Flur-al:POPL17} have extended 
the model to support mixed-size accesses.
Finally, Nienhuis~\etal~\cite{Nienhuis-al:OOPSLA16} presented 
a formal executable semantics in terms of an abstract machine, 
equivalent to the \CMM model. 

\paragraph{\JS Memory Model}

The \JSMM is based on the \CMM model. 
Like the latter, it also has the problem of thin-air values
and thus can only provide the internal \DRF guarantee. 
Contrary to the \CMM, the \JS model does not treat 
racy non-atomic accesses as undefined behavior. 

The main language primitive provided by the \JSMM
is \texttt{SharedArrayBuffer}, that is a linear mutable byte buffer.
Thus the model naturally supports mixed-size accesses.

\paragraph{A calculus for relaxed memory}

Crary and Sullivan~\cite{Crary-Sullivan:POPL15} proposed 
an alternative approach to the relaxed shared memory concurrency,
which they called \emph{Relaxed Memory Calculus} (\RMC).
Instead of deriving ordering constraints from annotations 
on memory accesses, they propose to directly specify 
the ordering between memory accesses in a source code. 
Their approach is highly generic and subsumes 
the traditional memory order annotations in the style of \CMM.
Their model is very weak and permits thin-air values. 
Yet the authors proved the internal \DRF theorem.

\paragraph{Relaxed Atomic + Ordering}

Saraswat~\etal~\cite{Saraswat-al:PPoPP07} presented the \RAO memory model
where relaxed behaviors are explained through transformations 
over a sequentially consistent execution.
Although the authors claim their model provides the external \DRF,
it also permits thin-air values. 
These two properties known to be incompatible~\cite{Batty-al:ESOP15}.
We suppose that the external \DRF can be achieved in their model 
only because of the fundamental restrictions on the input programming language 
(\eg the general conditional statements are not supported~\cite{PichonPharabod-Sewell:POPL16}). 

\paragraph{A theory of speculative computation}

Boudol and Petri~\cite{Boudol-Petri:ESOP10} proposed a general 
framework to study effects of speculative execution in
shared memory setting (\TSC). 
They have also noticed that the external \DRF does not 
hold in the presence of unrestricted speculations, 
yet the internal \DRF theorem still can be proven. 
