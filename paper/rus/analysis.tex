\section{Анализ}
\label{sec:analysis}

% We partitioned all models into six primary classes: 
% sequentially consistent models, models with total or partial order on stores, 
% program order preserving models, syntactic dependency preserving models, 
% semantic dependency preserving models, and model with out of thin-air values.

В этой главе мы обсуждаем введеные класы моделей памяти.
На основе данных из таблицы 
мы выводим взаимосвязи между оптимальностью схемы компиляции,
корректностью трансформаций и предоставляемыми гарантиями. 
В частности, мы демонстрируем как поддержка 
некоторых гарантий конфликтует с некоторыми трансформациями 
и как она влияет на оптимальность схемы компиляции. 

Мы начинаем с рассмотрения класса 
последовательно согласованных моделей~\cref{sec:analysis:seqcst}.
Затем мы переходим к моделям с линейным или 
частичным порядком на записях~\cref{sec:analysis:tso}.
После этого, мы рассматриваем класс наиболее слабых моделей 
допускающих значения из воздуха~\cref{sec:analysis:oota}.
Далее мы переходим к обсуждению различных подходов 
к решению проблемы значений из воздуха и рассмариваем модели, 
сохраняющие программный порядок~\cref{sec:analysis:porf},
синтаксические зависимости~\cref{sec:analysis:deprf} и
семантические зависимости~\cref{sec:analysis:sdeprf}.
 
В \cref{sec:analysis:other} мы отдельно обсуждаем некоторые 
конкретные свойства моделей, в частности, когерентность и возгорающуюся семантику. 
Факт наличия или отсутствия этих свойств ортогонален
разбиению на вышеупомянутые классы. 
Тем не менее наличие этих свойств у модели также влияет 
на корректность определенных трансформаций.

\subsection{Последовательная Согласованность}
\label{sec:analysis:seqcst}

Модель последовательной согласованности (\SC)
является наиболее интуитивной моделью конкурентности.
В рамках этой модели состояние памяти может быть 
представлено как просто отображение из 
адресов переменных в хранящиеся значения. 
Тогда каждый допустимый сценарий поведения программы 
может быть получен в результате поочередного последовательного
исполнения инструкций потоков. 

Многие распростаненные трансформации оказываются 
некорректными в модели \SC, включая 
все типы переупорядочивания инструкций, 
а также удаление общих подвыражений~\cite{Marino-al:PLDI11, Sevcik-Aspinall:ECOOP08}.
Тот факт что переупорядочивание инструкций запрещено 
делает эту модель очень дорогостоящей при реализации
на современных процессорах, так как даже 
относительно строгая модель памяти \Intel
допускает переупорядочивания типа запись/чтение. 
Таким образом, чтобы гарантировать последовательную согласованность, 
компилятор вынужден вставлять в код тяжеловесные 
барьеры памяти между инструкциями записи и чтения,
что делает схему компиляции далеко не оптимальной. 

Однако в терминах предоставляемых программисту гарантий 
модель \SC является весьма привлекательной. 
В частности, тривиальным образом гарантируется свойства \DRF и когерентности, 
так как модель присваивает программе только 
последовательно согласованные сценарии поведения. 

Концептуальная простота и привлекательность модели \SC 
вдохновила многих исследователей на попытки 
адаптации этой модели и смягчения накладываемых 
штрафов на время исполнения программы. 
Общей идеей данных работ была попытка 
отделения локальных (доступных только одному потоку) 
и разделяемых переменных.
Обращения к локальным переменным могут быть скомпилированы 
без добавления барьеров памяти, также к ним 
применим широкий спектр оптимизация корректных 
для случая однопоточных программ. 
Чтобы безопасным образом классифицировать 
локальные и разлеляемы переменные исследователи 
использовали системы типов~\cite{Vollmer-al:PPoPP17},
статический~\cite{Singh-al:ISCA12} или динамический анализ~\cite{Liu-al:PLDI19}, 
поддержку на аппаратном уровне~\cite{Singh-al:ISCA12, Marino-al:PLDI10}, 
или различные комбинации вышеупомянутых методов.  

Несмотря на эти усилия, модель \SC все равно имеет существенные накладные расходы. 
Например, при компиляции на процессоры семейства \ARMv{8}
замедление времени работы программ может достигать 70\%~\cite{Liu-al:PLDI19} 
(\see подробности в \cref{sec:catalog:sc}).
Более того, хотя вышеупомянутые техники обычно уменьшают 
накладные расходы на локальные обращения 
(которые, зачастую, чаще встречаются в программах),
они оказывают меньшее влияние на специфичные приложения, 
которые активно использую конкурентность, 
например, такие как неблокирующие структуры данных.
Наконец, требуется значительное количество усилий 
и технической работы, чтобы модифицировать 
современные компиляторы для поддержки модели \SC~\cite{Marino-al:PLDI11, Liu-al:PLDI19}.

\subsection{Линейный и частичный порядок на записях}
\label{sec:analysis:tso}

Следующий рассматриваемый класс моделей был вдохновлен моделями с 
\emph{линейным порядком на записях} (\emph{total store order}, \TSO)
и \emph{частичным порядком на записях} (\emph{partial store order}, \PSO)~\cite{Sparc:94}.
Модели \TSO и \PSO являются моделями семейств процессоров \Intel~\cite{Sewell-al:CACM10} 
и \SPARC~\cite{Sparc:94} соответственно. 
В этих моделям потоки оснащены \emph{буферами записей}.
Все операции записи сперва попадают в эти буферы, а уже 
затем переносятся в основную память. 

Для моделей этого класса схема компиляции под архитектуру \Intel 
является оптимальной, так как \Intel предоставляет модель \TSO.  
Однако при компиляции под архитектуры с более слабой моделью памяти, 
например~\POWER, необходимо использовать практический такое же 
количество барьеров, как и при компиляции из модели~\SC~\cite{Lustig-al:AISCA15}.

Модели этого класса допускают большее количество трансформаций кода чем \SC.
Использование буферов записи позволяет выполнять переупорядочивание 
типа запись/чтение в случае~\TSO, и также 
переупорядочивание типа запись/запись в случае~\PSO.

Хотя модели \TSO и \PSO слабее модели \SC, 
тем не менее они все ещё предоставляют довольно сильные гарантии, 
в частности, свойсва \DRF и когерентности.    

Таким образом, модели этого класса не имеют 
значительных преимуществ перед моделью \SC, 
и при этом влекут соизмеримые накладные расходы 
при компиляции под архитектуры c более слабой моделью памяти чем у \Intel. 
Следовательно, выбор этих моделей в качестве моделей для 
языка программирования оправдан только если предполагается 
поддержка компиляции только под процессоры архитектуры \Intel. 

\subsection{Значения из воздуха}
\label{sec:analysis:oota}

Далле мы переместимся на другой конец спектра моделей памяти
и рассмотрим класс, в который входят наиболее слабые модели
из рассматриваемых нами. 
Эти модели предоставляют оптимальные схемы компиляции и 
допускают практический любые разумные трансформации программ, 
но достигают этого ценой введения значений из воздуха 
(\cref{sec:background:oota}).

Рассмотрим вновь пример программы буфферизации чтения:

\begin{minipage}{0.43\linewidth}
\begin{equation*}
\small
\inarrII{
  \readInst{}{r_1}{x}     \\
  \writeInst{}{y}{1}      \\
}{
  \readInst{}{r_2}{y}     \\
  \writeInst{}{x}{r_2}    \\
}
\tag{LB}\label{ex:lbA}
\end{equation*}
\end{minipage}\hfill%
\begin{minipage}{0.09\linewidth}
\Large~\\ $\leadsto$
\end{minipage}\hfill%
\begin{minipage}{0.43\linewidth}
\begin{equation*}
\inarrII{
  \writeInst{}{y}{1}      \\
  \readInst{}{r_1}{x}     \\
}{
  \readInst{}{r_2}{y}     \\
  \writeInst{}{x}{r_2}    \\
}
\tag{LBtr}\label{ex:lbB}
\end{equation*}
\end{minipage}

Версия программы справа \ref{ex:lbB} может быть 
получена из программы слева \ref{ex:lbA} 
путем применения переупорядочивания инструкций типа чтение/запись. 
Результат ${[r_1=1, r_2=1]}$ допустим для программы \ref{ex:lbB}.
Тогда модель памяти, в которой переупорядочивание типа чтение/запись
является корректной трансформацией, также должна 
допускать этот результат для программы \ref{ex:lbA}.
Как было продемонстрировано в \cref{sec:background:oota}, 
для того чтобы получить такой результат, 
необходимо прибегнуть к спекулятивному исполнению. 

Мы также обсуждали, что не ограниченное 
спекулятивное исполнение может привести к появлению 
так называемых значений из воздуха, 
которые нарушают фундаментальные гарантии 
о поведении программ~%
\cite{Boehm-Demsky:MSPC14, Batty-al:ESOP15}, 
в частности, гарантии типобезопасности (type-safety)
и композициональности.  
Также не выполняется и гарантия внешней свободы от гонок (\eDRF).
Чтобы убедиться в этом, рассмотрим ещё один пример:

\begin{equation*}
\inarrII{
  \readInst{}{r_1}{x}      \\
  \kw{if} {(r_1)} ~\{      \\
  \quad\writeInst{}{y}{1}  \\
  \}
}{
  \readInst{}{r_2}{x}      \\
  \kw{if} {(r_2)} ~\{      \\
  \quad\writeInst{}{x}{1}  \\
  \}
}
\tag{LB+ctrl}\label{ex:lb+ctrl}
\end{equation*}

Для модель памяти, допускающей значения из воздуха, 
результат ${[r_1=1, r_2=1]}$ также является допустимым
(обоснование этого результата такое же как и для 
примера \ref{ex:lb+data} из \cref{sec:background:oota}).
Однако этот результат не только совершенно неинтуитивен, 
но и противоречит гарантии внешней свободы от гонок. 
Действительно, в модели \SC единственный допустимый 
сценарий поведения этой программы ведет к результату $[r_1=0, r_2=0]$ 
и не содержит никаких гонок, следовательно 
в модели, предоставляющей гарантию \eDRF, 
эта программа также должа иметь только этот единственный 
сценарий поведения. 

Контр-интуитивное поведение моделей 
допускающих значения из воздуха, 
а также тот факт что они нарушают множество 
важных гарантий о поведении программ, 
привело к консенсусу в исследовательском сообществе о том, 
что эти модели не подходят на роль моделей памяти 
для языков программирования~\cite{Boehm-Demsky:MSPC14, Batty-al:ESOP15}.  
Множество усилий было приложено для того, 
чтобы запретить проблематичные значения из воздуха, 
но в то же время сохранить оптимальность схем 
компиляции и корректность как можно большего количества трансформаций. 
В оставшейся части этой главы мы опишем различные 
способы борьбы с проблемой значений из воздуха. 

\subsection{Сохранение программного порядка}
\label{sec:analysis:porf}

The most straightforward way to forbid thin-air values 
was proposed by Boehm and Demsky~\cite{Boehm-Demsky:MSPC14}
The idea is to simply prohibit any kind of speculative execution, 
which can be achieved by forbidding load/store reorderings altogether. 
This fix not only restores the external \DRF~\cite{Lahav-al:PLDI17}
and other reasoning guarantees, but also leads to 
a much simpler model. The abstract machine implementing 
the memory model does not need to resort to speculative execution 
and can perform threads' instructions in-order. 
A memory storage can be implemented as a 
monotonically growing history of messages, 
with each thread having its own view on 
a frontier of this history~\cite{Dolan-al:PLDI18, Doherty-al:PPoPP19}.
% In terms of axiomatic semantics it is enough to just
% forbid cycles consisting of program order and reads-from relations. 

Lahav~\etal~\cite{Lahav-al:PLDI17} formalized this approach
to thin-air problem and studied it extensively. 
The authors shown that many program transformations 
are still sound in this setting, 
with the obvious exception of the load/store reordering itself
(see~\cref{table:cmp-cls} for details).

The compilation mapping to \Intel remain efficient, 
since this architecture already guarantee to preserve order 
between loads and subsequent stores. 
However, weaker architectures (\ARM, \POWER) do not guarantee that, 
and thus additional measures are required.
Boehm and Demsky~\etal~\cite{Boehm-Demsky:MSPC14} proposed to 
compile every relaxed load as 
a plain load followed by a spurious conditional branch,
which introduces a dependency between 
the load and subsequent stores. 
\ARM and \POWER hardware preserves this dependency, 
and thus it also retains the load/store ordering. 
Ou and Demsky~\cite{Ou-Demsky:OOPSLA18} studied 
a performance penalty required to preserve
load/store ordering between \textbf{relaxed atomics only}
on the \ARMv{8} hardware and reported a negligible overhead
of 0\% on average and 6.3\% in maximum on a set of benchmarks
implementing various concurrent data-structures, 
\eg locks, stacks, queues, deques, maps, \etc 
(see \ref{sec:catalog:porf} for details).
Note that the overhead is expected to be greater 
if the compilation scheme is required to preserve the ordering 
between non-atomic accesses as well. 

% In conclusion, the memory models forbidding load/store reorderings
% provide a simple solution to thin-air problem, 
% restore external \DRF-SC guarantee, preserve soundness of 
% most program transformations, induce no overhead when 
% compiled down to \Intel, and a moderate overhead 
% when compiled to \ARM or \POWER.

\subsection{Сохранение синтаксических зависимостей}
\label{sec:analysis:deprf}

The alternative conceptually simple solution 
to thin-air values problem is to preserve 
\emph{syntactic dependencies}~\cite{Boehm-Demsky:MSPC14, Alglave-al:ASPLOS18}.
Under this approach reordering of independent load/store pairs is allowed.
However, reordering is forbidden if a store depends on the value 
read by a load either because this value 
was used to compute the value written by the store (\emph{data dependency}), 
or it was used to compute 
the memory address of the store (\emph{address dependency}),
or else a control-flow path lead to the store was dependent
on this value (\emph{control dependency}).
For example, giving the program \ref{ex:lb+data} 
the store $\writeInst{}{y}{r_1}$ depends 
on the load $\readInst{}{x}{r_1}$ since 
it writes the value read by the load.

Note that these kind of dependencies are computed following a 
syntax of a program (hence the name) as opposed 
to \emph{semantic dependencies}.
For example, giving the modified version of 
the \ref{ex:lb+data} program below, 
the store to \texttt{y} is still considered 
to be dependent on the previous load. 

\begin{equation*}
\inarrII{
  \readInst{}{r_1}{x}           \\
  \writeInst{}{y}{1 + 0 * r_1}  \\
}{
  \readInst{}{r_2}{x}      \\
  \writeInst{}{x}{r_2}     \\
}
\tag{LB+fakedata}\label{ex:lb+fakedata}
\end{equation*}

Here the syntactic dependency can be eliminated 
by the \emph{constant folding} transformation --- 
the expression $1 + 0 * r_1$ can be reduced to value~$1$.
Under a syntactic dependency preserving memory model 
a compiler, however, is prohibited to perform this optimization. 
Indeed, once a dependency is removed, nothing prevents 
to reorder a store before a preceding load. 
Even if a compiler itself does not perform this reordering,
after the compilation hardware can 
do this during the execution.   

This subtlety reveals the main drawback of 
syntactic dependency tracking models --- 
trace preserving transformations
(\eg constant folding) are unsound in these models. 
Constant folding is one of the classic optimizations 
that any compiler might want to apply, 
and the fact that it is unsound  
makes an adoption of this class of models problematic.
Note that hardware memory models apply a similar approach 
and usually have a notion of syntactic dependencies between 
memory operations~\cite{Sarkar-al:PLDI11, Alglave-al:TOPLAS14, Pulte-al:POPL18}.
Yet in this setting the unsoundness of 
trace preserving transformations is not a problem,
since hardware does not perform such complex optimizations.

Ou and Demsky~\cite{Ou-Demsky:OOPSLA18} examined
the performance penalty of a syntactic 
dependency tracking compiler.
They adjusted compiler optimization passes to preserve
dependencies between \textbf{non-atomic and relaxed} accesses.
They evaluated the dependency preserving 
version of the \LLVM compiler infrastructure 
on \ARMv{8} hardware using \SPECCPU benchmarks
and reported a moderate slowdown of 
3.1\% on average and 17.6\% in maximum. 
(see \ref{sec:catalog:deprf} for details).

\subsection{Сохранение семантических зависимостей}
\label{sec:analysis:sdeprf}

The last approach to tackle thin-air problem is to   
construct a notion of \emph{semantic dependencies}, 
which would precisely characterize what load/store 
pairs are independent and rule out fake dependencies 
like the one in \ref{ex:lb+fakedata}.
A practical payoff of this approach is that it 
does not require significant modifications to existing compilers or hardware, 
and thus should not impose performance penalties.  
The ultimate goal is to enable the optimal compilation mappings, 
preserve most of the existing compiler optimizations, 
and at the same time maintain the important 
reasoning guarantees like external \DRF. 

It turns out that this task is quite challenging 
and to this date there is no strong consensus on how to achieve it.
In order to give a satisfactory definition of semantic dependencies 
researchers had to resort to conceptually complex memory models%
~\cite{Jagadeesan-al:ESOP10, Kang-al:POPL17, Jeffrey-Riely:LICS16, 
PichonPharabod-Sewell:POPL16, Chakraborty-Vafeiadis:POPL19, Paviotti-al:ESOP20}.
The main challenge in this line of work was to formally prove 
that these complex models indeed satisfy all the desired properties. 

Currently the most complete approach of this class 
is the \Promising semantics~\cite{Kang-al:POPL17, Lee-al:PLDI20}. 
This model was proven to enable the optimal compilation schemes~\cite{Podkopaev-al:POPL19}, 
and permit most local and global program transformations
(with a notable exception of the thread inlining), 
while still preserving the external \DRF guarantee.

\subsection{Вспомогательная классификация}
\label{sec:analysis:other}

We also identified an alternative division of memory models into groups, 
which correspond to particular properties of a memory model, 
namely the coherence and the catch-fire semantics which treats racy programs 
as erroneous. We demonstrate how presence of these properties 
affects the compilation mappings and the soundness of some program transformations.

\subsubsection{Модели с когерентностью}
\label{sec:analysis:coh}

The coherence property (\ie \SC-per-location, \cref{sec:background:coh})
has a subtle effect on the common subexpression elimination optimization (\CSE),
which was was first observed in the context of an early version of the \Java 
memory model~\cite{Pugh:JAVA99}.
To see the problem, consider the program below
(on the left) and the transformed version 
of this program after application of \CSE (on the right).
Note that the optimization has replaced 
the second access to variable \texttt{x}
by the read from register. 

\begin{minipage}{0.45\linewidth}
\begin{equation*}
\small
\inarrII{
  \readInst{}{r_1}{x}      \\
  \readInst{}{r_2}{y}      \\
  \readInst{}{r_3}{x}      \\
}{
  \writeInst{}{y}{1}       \\
}
\label{ex:coh-rr}
\end{equation*}
\end{minipage}\hfill%
\begin{minipage}{0.05\linewidth}
\Large~\\ $\leadsto$
\end{minipage}\hfill%
\begin{minipage}{0.45\linewidth}
\begin{equation*}
\small
\inarrII{
  \readInst{}{r_1}{x}      \\
  \readInst{}{r_2}{y}      \\
  \assignInst{r_3}{r_1}    \\
}{
  \writeInst{}{y}{1}       \\
}
\label{ex:coh-rr}
\end{equation*}
\end{minipage}

Now assume that variables \texttt{x} and \texttt{y} 
point to the same memory location.
Under this assumption the outcome $[r_1=0, r_2=1, r_3=0]$
is forbidden for a memory model respecting coherence.
Indeed, the coherence guarantees sequential consistency per location, 
which means that for programs consisting of accesses 
to a single memory location 
(as the one above in the presence of aliasing) 
only the sequentially consistent outcomes are allowed.
The outcome $[r_1=0, r_2=1, r_3=0]$ cannot be obtained 
as the interleaving of instructions, and thus 
it should be forbidden.  
However, this outcome is allowed for 
the optimized version of the program. 

Note that the compiler still can apply \CSE to the program above, 
but only if it is able to prove that variables \texttt{x} and \texttt{y} 
point to disjoint memory locations, which can be achieved 
by the means of an alias analysis~\cite{Diwan-al:PLDI1998}.
In fact, in this case \CSE can be seen as a combination 
of instructiong reordering and elimination transformations.  

Therefore, the coherence property in general is not compatible 
with the common subexpression elimination.
As for compilation schemes, coherence does not require 
any changes here and thus does not impose any performance penalty.
It is because hardware models already guarantee coherence%
~\cite{Alglave-al:TOPLAS14, Sarkar-al:PLDI11, Sewell-al:CACM10, Lahav-al:PLDI17}. 

\subsubsection{Модели с возгорающейся семантикой}
\label{sec:analysis:ub}

A catch-fire semantics which treats racy non-atomic 
accesses as undefined behavior also affects  
soundness of program transformations. 
As we already briefly discussed, it enables 
the optimal compilation mapping for non-atomic accesses and 
makes sequentially valid transformations applicable 
to them, but its impact is not limited to this observation. 
A catch-fire semantics also has an interesting interplay
with the speculative load introduction.

Consider the following example:

\begin{minipage}{0.43\linewidth}
\begin{equation*}
\small
\inarrII{
  \readInst{}{r}{x}      \\
  \kw{if} {(r)} ~\{      \\
  \quad\readInst{}{s}{y} \\
  \}

}{
  \writeInst{}{y}{1}       \\
}
\label{ex:sliA}
\end{equation*}
\end{minipage}\hfill%
\begin{minipage}{0.09\linewidth}
\Large~\\ $\leadsto$
\end{minipage}\hfill%
\begin{minipage}{0.43\linewidth}
\begin{equation*}
\inarrII{
  \readInst{}{r_1}{x}      \\
  \readInst{}{t}{y}        \\
  \kw{if} {(r)} ~\{        \\
  \quad\assignInst{s}{t}   \\
  \}

}{
  \writeInst{}{y}{1}       \\
}
\label{ex:sliB}
\end{equation*}
\end{minipage}
 
As we mentioned in \cref{sec:background:trans}, 
the speculative load introduction can be used 
in combination with the load/load elimination 
to move a load instruction out of one branch of a conditional.
In more detail, giving the example above, 
the speculative load introduction can be applied
to add the load $\readInst{}{t}{y}$ before the $\kw{if}$ statement, 
and then the load/load elimination can be used 
to replace the second load with an assignment. 

The subtle point here is that while the 
left program is race free even under \SC, 
the right program is racy under \SC semantics,
because of the race between load and store to \texttt{y}.
This fact implies that if all accesses in the programs above 
are non-atomic, then a catch-fire semantics should 
treat the right program as having undefined behavior.
In other words, the right program allows any outcome,
while the left program allows only the outcome ${[r=0]}$.
Soundness of program transformation requires 
a set of outcomes of a transformed program 
to be a subset of outcomes of the original program. 
This condition is clearly violated in our example. 

Put simply, speculative load introduction in general
is unsound in catch-fire memory models, 
because it can bring data-races into otherwise 
race-free programs. Since catch-fire semantics
is sensitive to the presence of data-races 
it is incompatible with this transformation. 

Note that this problem cannot be mitigated 
by forbidding only non-atomic load introduction
and allowing atomic load introduction. 
Indeed, an introduced atomic load access still 
can race with some non-atomic load or store
located elsewhere in a program.  
