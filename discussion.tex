\section{Discussion}
\label{sec:discussion}

In this section we provide a summary of our findings
%% We again briefly compare various classes of memory models 
and present a short guide for researchers and system-level developers 
on how to choose a memory model based on 
design principles of a programming language.   

A language that seeks to provide a clear semantics and 
high-level programming abstractions at the cost 
of some performance losses most definitely should 
adhere to simple memory models like the sequential consistency. 
%% , \eg \Haskell,
%% \app{I doubt that Haskell is a good example in this regard.
%%   It is lazy and loosely defines execution order.}

Programming languages focusing on efficiency 
of compiled code, for example, \CPP, 
have to resort to weakest models admitting 
the optimal compilation mapping 
and wide range of program transformations. 
For these languages it would be natural 
to pick semantic dependency preserving models.
However, these models are the most complicated ones
which makes reasoning about programs' correctness under them challenging.
\app{Cite Svendsen-al-ESOP18 here.}

In the middle between two extremes are program order preserving and 
syntactic dependency preserving models.
Those are a reasonable choice for programming languages
which may afford a moderate performance overhead 
in exchange of a simpler and more predictable program behavior~\cite{Ou-Demsky:OOPSLA18}.
% An example of such language is \OCaml --- 
% a high-level programming language 
% with an emphasis on functional paradigm which is 
% at the same time is actively used in performance sensitive areas
% like the development of compilers and verification tools. 

For languages adopting stronger models which require non-optimal
compilation mappings and forbid certain program transformations
there are some general optimization techniques and design decisions
which may partly mitigate the induced performance penalties.

A type system can serve as a great help in this task. 
Languages like \Haskell, \OCaml, \Rust that 
statically distinguish and isolate memory regions 
which can be accessed and modified concurrently have a great advantage.
These languages can identify precisely 
immutable and thread local variables
and compile accesses to them without insertion of fences.
Moreover, memory accesses to local variables are subject to 
a wide range of program transformations proven to be
sound for single threaded programs. 
 
Languages like \Java which cannot utilize the type system 
to fully prevent racy accesses to non-atomic variables 
because of the backward compatibility, still can 
approximate a set of thread local variables    
using a conservative static escape analysis~\cite{Choi-al:OOPSLA1999}
or various dynamic techniques~\cite{Liu-al:PLDI19},
and then apply similar optimizations to them. 

Functional programming languages encourage 
programmers to use immutable data whenever possible.
This style of programming minimizes the use 
shared memory and mitigates the performance impact 
of a strong memory model~\cite{Vollmer-al:PPoPP17}. 

Finally, if the language tolerates undefined behavior, as \CPP does, 
an alternative to a complex semantic dependency preserving model
could be a program order preserving model (or a syntactic dependency preserving one) 
which treats data races on non-atomic accesses as 
undefined behavior~\cite{Boehm-Demsky:MSPC14, Ou-Demsky:OOPSLA18}.
In this case a compiler can use optimal compilation mappings 
and apply a wide range of transformations to non-atomics 
and at the same time have a simpler semantics for atomics.

\paragraph{Choosing a memory model for Kotlin}
As a example, %% of choosing a memory model for a language,
let's consider Kotlin%
\footnote{https://kotlinlang.org/},
a general-purpose programming language,
which does not have a standardized memory model yet.
Currently, Kotlin is compilable to JVM, JavaScript, and native platforms
(Linux, Windows, macOS, iOS, \etc) via LLVM.

\app{TODO: continue}
