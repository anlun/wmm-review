\section{Criteria for Memory Models}
\label{sec:background}

In this section we will have a closer look on criteria for 
programming language memory models, 
namely an optimality of the compilation scheme, 
soundness of common program transformations, 
and provided reasoning guarantees.  
But first we need to introduce the 
programming primitives provided by the shared memory abstraction, 
and the various styles of formal semantics 
used to specify the memory model. 

\subsection{Programming Primitives}
\label{sec:background:primitives}


The memory model defines the semantics of the shared memory 
in the presence of concurrently executing threads. 
More concretly, the memory model 
defines which values reads of shared variables 
can observe at each point of execution. 
Therefore the main abstraction of the memory model 
is the shared memory itself. 
The shared memory consists of a individual shared variables, 
each having unique address~\footnote{
Throughout the rest of paper, we use terms 
memory address and memory location interchangeably}.
Threads can access these variables by performing 
loads or stores~\footnote{We also use the terms 
load/stores and reads/writes interchangeably}.

\begin{figure}[t]
\[\def\arraystretch{1.2}
  \begin{array}{ll} 
    \readInst{o}{r}{x}                  & \text{Load}                   \\ 
    \writeInst{o}{x}{v}                 & \text{Store}                  \\ 
    \readArrayInst{o}{r}{x}{i}{j}       & \text{Mixed Size Load}        \\ 
    \writeArrayInst{o}{x}{v}{i}{j}      & \text{Mixed Size Store}       \\ 
    \casInst{o}{r}{x}{v_e}{v_d}         & \text{Compare-and-Swap}        \\ 
    \faddInst{o}{r}{x}{v}               & \text{Fetch-and-Add}          \\ 
    \lockInst{l}                        & \text{Lock}                   \\ 
    \unlockInst{l}                      & \text{Unlock}                 \\ 
    \fenceInst{o}                       & \text{Fence}                  \\ 
    x \in \mathsf{Var}                  & \text{Shared Variables}       \\ 
    r \in \mathsf{Reg}                  & \text{Thread-Local Registers} \\ 
    v \in \mathsf{Val}                  & \text{Values}                 \\ 
    l \in \mathsf{Lock}                 & \text{Locks}                  \\ 
    i,j \in \mathsf{Index}              & \text{Array Indices}          \\ 
    o \in \set{\na,\rlx,\acqrel,\sco}   & \text{Access Modes}           \\ 
  \end{array}
\]
\caption{Primitives of relaxed memory models}
\label{fig:wmm-abs}
\end{figure}

Most programming language memory models distinguish 
\emph{non-atomic} (sometimes also called \emph{plain})
and \emph{atomic} variables. 
The former generally should not be accessed 
concurrently from parallel threads. 
Depending on the particular programming language, 
concurrent accesses to non-atomic variables 
can be either prevented by the type-system 
(\eg \Haskell~\cite{Marlow-al:Haskell10, Vollmer-al:PPoPP17}, \Rust~\cite{RustBook:19}), 
have undefined behavior (\eg \CPP~\cite{Boehm-Adve:PLDI08, Batty-al:POPL11}), 
or have defined but very weak semantics with almost 
no guarantees on the order of accesses to non-atomics
that concurrent threads can observe (\eg \Java~\cite{Manson-al:POPL05}).

In addition to this some memory models distinguish 
several kinds of accesses to atomic variables.
In these models the accesses to shared memory are annotated by the 
so-called \emph{access modes}.
For example, the \CPP model (and a later revision of 
\Java~\cite{Bender-Palsberg:OOPSLA19}), distinguish 
three modes: \emph{relaxed} (\emph{opaque} in \Java terminology), 
\emph{acquire/release}, and \emph{sequentially consistent}.
They are denoted as $\rlx$, $\opq$, $\acqrel$, and $\sco$ correspondingly.
Non-atomic accesses are often considered to be the fourth access mode $\na$, 
but note that mixing non-atomic and atomic accesses to the same variable 
entails undefined behavior in \CPP.

The access modes are ordered by the guarantees they provide
in exchange of optimization opportunities, as the following 
diagram shows.

$$ \na \sqsubseteq \rlx \sqsubseteq \acqrel \sqsubseteq \sco $$

On the one end of the spectrum are sequentially consistent accesses. 
They guarantee to restore the \SC semantics, if used properly 
(see \cref{sec:background:drf} for details).
Non-atomic accesses, as we have already discussed, give 
from little to no guarantee. 
Relaxed accesses also have very weak guarantees, 
usually they provide the so-called \emph{coherence} property
(see \cref{sec:background:coh} for details).
Finally, in the middle there are the acquire/release accesses. 
They are designed to support the message passing idiom~\cite{Lahav-al:POPL16}.
The thread sends the message by performing a release write, 
the thread expecting a message can perform an acquire read. 
If the acquire read observes the release write, the two 
threads ``synchronize''. 

The memory model can also provide atomic \emph{read-modify-write} operations.
These include \emph{compare-and-swap}, and variations of atomic increment,
\eg \emph{fetch-and-add}, \emph{fetch-and-sub}, \etc 
Compare-and-swap (\CAS) operation takes the shared variable, the expected 
and the desired values. It reads the content of the variable
and compares it with the expected value. If the two are equal,
it substitutes the content of the variable to desired value. 
In either case, the value read from the variable is returned as a result. 
Note that the above operations is guaranteed to be performed atomically, 
no other write to the shared variable may happen ``in-between'' 
read and write parts of \CAS.
Fetch-and-add and similar primitives perfrom 
the operation (addition, substraction,~\emph{etc.}~)
atomically and unconditionally, returning 
the content of the shared variable prior to modification.  

Locks sometimes considered to be a part 
of the memory model~\cite{Manson-al:POPL05}, 
as well as memory fence operations~\cite{Batty-al:POPL11},
corresponding to hardware fence instructions
(see \cref{sec:background:compile} for details). 

Finally, the memory model can treat the shared memory 
not as set of disjoint typed variables, but rather as 
a raw byte sequence, and permit so-called \emph{mixed-size} 
concurrent accesses~\cite{Flur-al:POPL17}. 

% , as in the example below 
% (assume $\declareArray{x}{0}{7}$ is byte array of size~\texttt{8}). 

% \begin{align*}
% \inarrIII{
%   \writeArrayInst{}{x}{1}{0}{3}
% }{
%   \writeArrayInst{}{x}{1}{4}{7}
% }{
%   \readArrayInst{}{r}{x}{0}{7}
% }
% \tag{Mixed-Size}\label{ex:mixsz}
% \end{align*}

\subsection{Formal Semantics}

\subsection{Compilation Scheme}
\label{sec:background:compile}

We next consider the first criterion for 
programming language memory models --- 
an optimality of compilation scheme. 
A compilation scheme is a mapping of 
programming language primitives into 
instructions of particular hardware architecture. 
In our setting we consider the primitives 
mentioned in \cref{sec:background:primitives}.
The hardware architectures provide a similar set 
of instructions which usually contain 
plain load and stores\footnote{Some architectures 
also provide various types of load and stores
matching the access modes annotations, 
\eg \texttt{lda} --- load acquire, 
and \texttt{stl} --- store release on \ARMv{8}}, 
read-modify-write operations, 
and also various memory fences.    

The compilation mapping should be \emph{sound}.
In the context of this paper it means that 
the set of outcomes permited by the 
memory model of the hardware should be 
a subset of outcomes permited by the 
programming language model. 

Let us consider an example. 
The program \ref{ex:sb} below is a 
fragment of the \ref{ex:Dekker} program 
from the \cref{sec:intro}.
Assume the memory model of the programming language
is sequential consistency, and we want 
to compile for \xTSO hardware. 
Then if one compile all loads and stores 
to plain load and store instructions of \xTSO,
the outcome $[r_1=0, r_2=0]$ would be 
allowed for the compiled program 
(and it can actually be observed in practice), 
since the memory model of \xTSO permits this outcome. 
It can be obtained as a result of \emph{store buffering}
optimization (hence the name of the program \ref{ex:sb}). 
The store $\writeInst{}{x}{1}$ can be buffered and 
executed after all other instructions of the program.  
Yet clearly the outcome $[r_1=0, r_2=0]$ is not sequentially consisestent. 
Therefore the proposed compilation scheme, 
which maps all load and stores to the plain one is unsound. 
As we have demonstrated in \cref{sec:intro} 
the unsoundness of compilation scheme has 
dramatic consequences, as it may break 
the correctness of the program. 

\begin{minipage}{0.45\linewidth}
\begin{equation*}
\inarrII{
   \writeInst{}{x}{1}   \\
   \emptyInst           \\
   \readInst{}{r_1}{y}  \\
}{
  \writeInst{}{y}{1}   \\
  \emptyInst           \\
  \readInst{}{r_2}{x}  \\
}
\tag{SB}\label{ex:sb}
\end{equation*}
\end{minipage}\hfill%
\begin{minipage}{0.45\linewidth}
\begin{equation*}
\inarrII{
   \writeInst{}{x}{1}   \\
   \mfenceInst          \\
   \readInst{}{r_1}{y}  \\
}{
  \writeInst{}{y}{1}   \\
  \mfenceInst          \\
  \readInst{}{r_2}{x}  \\
}
\tag{SB+MFENCE}\label{ex:sb-mfence}
\end{equation*}
\end{minipage}

A sound compilation scheme for sequential consistency 
can compile the stores as plain stores followed 
by the \texttt{mfence} instruction~\cite{Sewell-al:CACM10, Batty-al:POPL11}, 
as demonstrated in \ref{ex:sb-mfence}. 
The \texttt{mfence} is a special memory fence instruction
of \xTSO architecture which flushes the store buffer of the thread. 
For the program \ref{ex:sb-mfence} the outcome $[r_1=0, r_2=0]$
is forbidden by the \xTSO memory model. 

Although the modified compilation scheme is sound for \SC, 
it is not \emph{optimal}, in a sense that 
it requires to use memory fence instructions, 
which usually induces a performance penalty~\cite{Marino-al:PLDI11, Liu-al:OOPSLA17}.
Unfortunately, it is not possible to have compilation mapping 
for \SC model which is both \emph{sound and optimal}, 
assuming the modern hardware architectures.     
This fact makes \SC memory model unsuitable  
for the high-performance programming languages
and serves as one of the stimuls for the weakening 
of the memory model. 
 
In this paper, when speaking about the compilation schemes, 
we will consider the following hardware memory models:
\xTSO, \POWER, \ARMv{7}, and \ARMv{8}. 
This is for two main reasons. 
First, these hardware architectures are the 
most widespread today~\cite{}. 
Second, they have received a lot of attention 
from the research community recently. 
As the result of this effort, 
there were developed a rigorous formal 
specifications of these models~%
\cite{Sewell-al:CACM10, Sarkar-al:PLDI11, 
Flur-al:POPL16, Pulte-al:POPL18}. 

\subsection{Program Transformations}
\label{sec:background:trans}

The next criterion for memory model is 
soundness of program transformations. 
Program transformations are a source-to-source
transfromations of the code which are applied 
during the optimization passes of the compiler. 

\emph{Sound} transformations should preserve the semantics 
of the program. In our context, similarly to the 
soundness of compilation scheme, it means that 
the set of outcomes of the transformed program 
should be a subset of outcomes of the original one. 

Going back to the \ref{ex:sb} example, 
assume the sequential consistency model again and
consider a transformation that reorders 
a store instruction past the following load 
instructions, assuming the load and store
operate on disjoint memory locations.

\begin{minipage}{0.45\linewidth}
\begin{equation*}
\inarrII{
   \writeInst{}{x}{1}   \\
   \readInst{}{r_1}{y}  \\
}{
  \writeInst{}{y}{1}   \\
  \readInst{}{r_2}{x}  \\
}
% \tag{SB}\label{ex:sb-src}
\end{equation*}
\end{minipage}\hfill%
\begin{minipage}{0.05\linewidth}
\Large~\\ $\leadsto$
\end{minipage}\hfill%
\begin{minipage}{0.45\linewidth}
\begin{equation*}
\inarrII{
   \readInst{}{r_1}{y}  \\
   \writeInst{}{x}{1}   \\
}{
  \writeInst{}{y}{1}   \\
  \readInst{}{r_2}{x}  \\
}
% \tag{SBtr}\label{ex:sb-tgt}
\end{equation*}
\end{minipage}

For the transformed version of the program (on the right),
the outcome $[r_1=0, r_2=0]$ is sequentially consistent.
Yet for the original one (on the left) it is not. 
It means that the aforementioned program transformation
is unsound for \SC. 

We next present a comprehensive list of 
various program transformations considered in
the literature on weak memory models 
with a short description of each one.
Note that it is far from being a complete list of 
transformations used in optimizing compilers~\cite{Muchnick:ACDI97}.
For example it lacks common loop optimizations, 
because the theory of relaxed memory models still
strugles with problems of liveness properties, 
needed to study these transformations formally. 

The transformations we consider can be split into 
two subcategories: \emph{local} and \emph{global}.
Local transformations rewrite a small 
piece of code within a single thread.
Global transformations may need to consider 
the whole program (or a large part of it) 
spanning multiple threads in order 
to perform the rewriting.       
 
\subsubsection{Local Transformations}

\paragraph{Reordering of Independent Instructions} 

This transformation reorders two 
adjucent independent memory accessing instructions
operating on different memory locations.
Depending on the particular pair of instructions
it can be further split into store/load, store/store, 
load/load, and load/store reorderings.  
%
\[\def\arraystretch{1.4}\footnotesize
  \begin{array}{cccl} 

      \writeInst{}{x}{v} \seq \readInst{}{r}{y} 
    & \leadsto 
    & \readInst{}{r}{y} \seq \writeInst{}{x}{v}
    & \text{store/load}  \\ 

      \writeInst{}{x}{v} \seq \writeInst{}{y}{u} 
    & \leadsto 
    & \writeInst{}{y}{u} \seq \writeInst{}{x}{v}
    & \text{store/store}  \\ 

      \readInst{}{r}{x} \seq \readInst{}{s}{y} 
    & \leadsto 
    & \readInst{}{s}{y} \seq \readInst{}{r}{x}
    & \text{load/load}  \\ 

      \readInst{}{r}{x} \seq \writeInst{}{y}{v} 
    & \leadsto 
    & \writeInst{}{y}{v} \seq \readInst{}{r}{x}
    & \text{load/store}  \\ 

  \end{array}
\]

\paragraph{Elimination of Redundunt Access} 

In a pair of two adjacent memory access instructions 
one of them can be eliminated if its effect 
is subsumed by the another. 
For example, the two stores writing to the same variable 
can be replaced by a single store.  
Similarly to reorderings, there exist four kinds 
of eliminations depicted below. 
%
\[\def\arraystretch{1.4}\footnotesize
  \begin{array}{cccl} 

      \writeInst{}{x}{v} \seq \readInst{}{r}{x} 
    & \leadsto 
    & \writeInst{}{x}{v} \seq \assignInst{r}{v}
    & \text{store/load}  \\ 

      \readInst{}{r}{x} \seq \readInst{}{s}{x} 
    & \leadsto 
    & \readInst{}{r}{x} \seq \assignInst{s}{r}
    & \text{load/load}  \\ 

      \readInst{}{r}{x} \seq \writeInst{}{x}{r} 
    & \leadsto 
    & \readInst{}{r}{x} 
    & \text{load/store}  \\ 

      \writeInst{}{x}{v} \seq \writeInst{}{x}{u} 
    & \leadsto 
    & \writeInst{}{x}{u}
    & \text{store/store}  \\ 

  \end{array}
\]

\paragraph{Irrelevant Load Elimination}

Yet another elimination transformation 
which removes the load instruction if its 
result is never used. 
%
\[\def\arraystretch{1.4}\footnotesize
  \begin{array}{cccl} 

      \readInst{}{r}{x} 
    & \leadsto 
    & \epsInst
    & ~|~ \text{$r$ is never used}  \\ 

  \end{array}
\]

\paragraph{Speculative Load Introduction}

The inverse to the previous transformation, 
the load instroduction inserts a load instruction 
in an arbitary place of the program.
%
\[\def\arraystretch{1.4}\footnotesize
  \begin{array}{cccl} 

      \epsInst
    & \leadsto 
    & \readInst{}{r}{x} 
    & ~|~ \text{$r$ is never used}  \\ 

  \end{array}
\]

It can be used in combination with 
load/load elimination to move a load 
instruction out from one branch of 
the conditional.
%
\[\def\arraystretch{1.4}\footnotesize
  \begin{array}{ccc} 

      \kw{if} (e)~ \kw{then} \{ \readInst{}{r}{x} \}
    & \leadsto 
    & \readInst{}{s}{x} \seq \kw{if} (e)~ \kw{then} \{ \assignInst{r}{s} \} \\
    & & ~|~ \text{$s$ is never used}  \\ 

  \end{array}
\]

\paragraph{Roach Motel Reordering}

This class of reorderings moves memory access instructions
into synchronization blocks. For example, a store 
can be moved past a lock acquisition. 
Intuitively, such reorderings can only increase 
the synchronization of the program, 
which means that the transformed program should 
exhibit less non-determinism and have fewer outcomes. 

Non-atomic accesses can be moved freely inside 
a critical section, \ie past a lock acquisition
or prior a lock release. 
Besides that, a non $\sco$ store can be moved after \texttt{lock}, 
and non $\sco$ load can be moved prior \texttt{unlock}.   
Similar rules apply to reordeings around 
acquire and release accesses and fences, 
where an acquire operation behaves similarly to \texttt{lock}, 
and release operation similarly to \texttt{unlock}.
% %
\[\def\arraystretch{1.4}\footnotesize
  \begin{array}{cccl} 

      \readInst{\na}{r}{x} \seq \lockInst{l} 
    & \leadsto 
    & \lockInst{l} \seq \readInst{\na}{r}{x}
    & ~ \\ 

      \writeInst{o}{x}{v} \seq \lockInst{l} 
    & \leadsto 
    & \lockInst{l} \seq \writeInst{o}{x}{v}
    & ~|~ o \sqsubset \sco  \\ 

      \unlockInst{l} \seq \writeInst{\na}{x}{v} 
    & \leadsto 
    & \writeInst{\na}{x}{v} \seq \unlockInst{l}
    & ~ \\ 


      \unlockInst{l} \seq \readInst{o}{r}{x} 
    & \leadsto 
    & \readInst{o}{r}{x} \seq \unlockInst{l}
    & ~|~ o \sqsubset \sco  \\ 

  \end{array}
\]


\paragraph{Strengthening}

Similarly to the roach motel reordeing, the strengthening
transformation increases the synchronization by 
replacing an access mode of an operation by a stronger one. 
For example, a non-atomic access can be replaced by 
a sequentially consistent access. 
%
\[\def\arraystretch{1.4}\footnotesize
  \begin{array}{cccl} 

      \readInst{o}{r}{x} 
    & \leadsto 
    & \readInst{o'}{r}{x}
    & ~|~ o \sqsubset o' \\ 

      \writeInst{o}{x}{v}
    & \leadsto 
    & \writeInst{o'}{x}{v}
    & ~|~ o \sqsubset o'  \\ 

  \end{array}
\]

\paragraph{Trace Preserving Transformations}

This wide class contains all local transformations 
which do not change the set of traces of a thread. 
An example is classic \emph{constant folding}%
~\cite{Muchnick:ACDI97, Wegman-Zadeck:TOPLAS91} transformation.
Below is particular example of constant folding application.
%
\[\def\arraystretch{1.4}\footnotesize
  \begin{array}{cccl} 

      \writeInst{}{x}{0 + v} 
    & \leadsto 
    & \writeInst{}{x}{v}
    & \\ 

  \end{array}
\]
  
\paragraph{Common Subexpression Elimination}

Yet another classic transformation~\cite{Muchnick:ACDI97} 
which searches for instances of identical expressions 
and removes the redundunt computations. 
Below is an example. 
%
\[\def\arraystretch{1.4}\footnotesize
  \begin{array}{cccl} 

      \readInst{}{r_1}{x + y} \seq \readInst{}{r_2}{x + y} 
    & \leadsto 
    & \readInst{}{r_1}{x + y} \seq \readInst{}{r_2}{r_1}
    & \\ 

  \end{array}
\]

\subsubsection{Global Transformations}

\paragraph{Register Promotion}

If the compiler can determine that a shared variable 
is accesses only from a single thread, it can replace 
the variable by a thread-local register. 
%
\[\def\arraystretch{1.4}\footnotesize
  \begin{array}{ccl} 

      \writeInst{}{x}{v} \seq \readInst{}{r}{x} 
    & \leadsto 
    & \assignInst{s}{v} \seq \assignInst{r}{s}
    \\ 
    
    & & |~ \text{\texttt{x} is not accessed from other threads} \\
    & & |~ \text{\texttt{s} is a fresh register} \\ 

  \end{array}
\]

\paragraph{Thread Inlining}

Sequentialization or thread inlining 
merges two threads into one. 
%
\[\def\arraystretch{1.4}\footnotesize
  \begin{array}{cccl} 

      P \pll Q 
    & \leadsto 
    & P ~\seq Q
    & ~ \\ 
    
  \end{array}
\]


\paragraph{Value Range Based Transformations}

Transformation of this class can be applied 
if a program satisfies some invariant deduced 
by a global value-range analysis. 
For example, in a program below   
the conditional statement can be eliminated 
since a static analysis can deduce an invariant 
$\mathsf{x} \geq \mathsf{0}$.

{\footnotesize
\begin{minipage}{0.45\linewidth}
\begin{equation*}
\inarrII{
   \readInst{}{r_1}{x}             \\
   \kw{if} (r_1 \geq 0) ~\kw{then} \\
   \quad\writeInst{}{y}{1}         \\
}{
  \readInst{}{r_2}{x}               \\
  \writeInst{}{y}{r_2}              \\
}
\end{equation*}
\end{minipage}\hfill%
\begin{minipage}{0.05\linewidth}
\Large~\\ $\leadsto$
\end{minipage}\hfill%
\begin{minipage}{0.4\linewidth}
\begin{equation*}
\inarrII{
   \readInst{}{r_1}{x}             \\
   \writeInst{}{y}{1}              \\
}{
  \readInst{}{r_2}{x}               \\
  \writeInst{}{y}{r_2}              \\
}
\end{equation*}
\end{minipage}
}

\subsection{Reasoning Guarantees}

\subsubsection{DRF Theorems}
\label{sec:background:drf}

% \begin{itemize}
%   \item Motivation: no weak behaviors for well-sync programs.
%   \item Example
%   \begin{itemize}
%     \item Lock + increment?
%     \item MP with atomic flag?
%   \end{itemize}
%   \item Definition of the race
%   \item DRF theorem
%   \begin{itemize}
%     \item explain difference between internal/external DRF
%   \end{itemize}
%   \item Local DRF (?)
%   \begin{itemize}
%     \item Example
%   \end{itemize}
% \end{itemize}

\subsubsection{Coherence}
\label{sec:background:coh}

\subsubsection{Undefined Behavior}
\label{sec:background:ub}

\subsubsection{Out-of-Thin-Air Values}
\label{sec:background:oota}

% \begin{itemize}
%   \item Introduce three examples: LB, LB+dep, LB+fakedep.
%   \item Explain the problem: some memory models cannot 
%     correctly distinguish theese three programs.
%   \item It leads to out-of-thin-air values.
% \end{itemize}

% \begin{equation*}
% \inarrII{
%   \readInst{}{r_1}{x}      \\
%   \writeInst{}{y}{r_1}     \\
% }{
%   \readInst{}{r_2}{x}      \\
%   \writeInst{}{x}{r_2}     \\
% }
% \tag{LB+data}\label{ex:lb+data}
% \end{equation*}


% \subsubsection{$\lPO\cup\lRF$ Acyclicity}

% \begin{itemize}
%   \item Motivation: forbid OOTA.
%   \item Proposed solution: forbid causality cycles. 
%   \item Explain execution graphs and $\lPO\cup\lRF$ cycles.
%   \item LB examples againg, with their execution graphs.
%   \item Drawback of this approach: some optimizations are unsound 
%     (refer to analysis section).
% \end{itemize}

% \subsubsection{Syntactic Dependency Tracking}

% \begin{itemize}
%   \item Motivation: forbid OOTA, but enable more opts.
%   \item Proposed solution: forbid causality cycles with syntactic dependencies. 
%   \item Explain $\lPPO\cup\lRF$ cycles.
%   \item LB examples againg, with their execution graphs and syntax.deps.
%   \item Drawback of this approach: some optimizations are still unsound 
%     (refer to analysis section).
% \end{itemize}

% \subsubsection{Semantic Dependency Tracking}

% \begin{itemize}
%   \item Motivation: forbid OOTA (precisely).
%   \item Proposed solution: forbid causality cycles with semantic dependencies. 
%   \item The exact notion of semantic dependency is model-specific.
%         There is no conventional common definition.
%   \item Drawback of this approach: complexity, no common ground.
% \end{itemize}

% \begin{itemize}
%   \item Motivation: enable more opts for non-atomics.
%         (At the cost of model's predictability and programmability).
%   \item Catch-fire semantics (race on non-atomics implies UB).
%   \item Explain how it affects opts.
% \end{itemize}


