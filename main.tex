\documentclass[a4paper,twoside,11pt]{article}
\usepackage[cp1251]{inputenc}
\usepackage[english,russian]{babel}
\usepackage{fancyhdr}
\usepackage{newprog1e}
\usepackage{amsfonts,amsmath,amssymb,amsthm}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{xcolor}
\usepackage{tikz}
\usepackage{cleveref}

\tolerance=1000

\newcommand{\defi}{\stackrel{\mathrm{def}}{=}}

\numberwithin{equation}{section}
\newtheorem{theorem}{Theorem}

\newtheorem{definition}{Definition}

\journalnumber{2}
\curyear{2020}
\authorlist{}
\titlehead{}
\headerdef

\udk{004.421.6}
%92+004.94}
\rubrika{}
\dateinput{01.12.2020}

\rusabstr{}

\author{Anonymous Authors}
\title{A Survey of Programming Language Memory Models}
%\thanks{~}

\date{}

\input{defs.tex}

\begin{document}

\maketitle
%\tableofcontents

\begin{abstract}
\end{abstract}

\section{Introduction}
A main challenge in concurrent programming is 
to establish a proper synchronization between threads executed in parallel.     
Usually it is done with the help of synchronization primitives
provided by the programming language or libraries,
for example locks, barriers, channels \etc
If the accesses to mutable shared variables are not 
protected by syncronization primitives, then program can contain \emph{data-races}.
A data-race occurs when two threads concurrently access the same shared location 
and at least one of them is performing a write operation.
Data-races serve as a source of bugs, 
which are hard to detect due to nondeterministic nature of concurrent programs.

Unfortunately, data-races are unavoidable in some cases. 
For example, the implementation of synchronization primitives 
themselves usually contain data-races.
Thus it is important to specify the behaviour of programs containing data-races.
This is what the memory model of programming language is responsible for.  
The memory model defines which values reads of shared variables can observe at each point of execution. 
%In other words, it defines the semantics of concurrent program.

Let us consider the consequences of having data-races on a concrete example.
Here is a simplified version of Dekker's algorithm for mutual exclusion.

\begin{equation*}
\inarrII{
  \writeInst{}{x}{1} \\
  \readInst{}{r_1}{y}  \\
  \kw{if} {r_1 = 0} ~\{ \\
  ~~ \comment{critical section} \\
  \}
}{
  \writeInst{}{y}{1} \\
  \readInst{}{r_2}{x}  \\
  \kw{if} {r_2 = 0} ~\{ \\
  ~~ \comment{critical section} \\
  \}
}
\tag{Dekker}\label{ex:Dekker}
\end{equation*}

In this program there are two threads accessing shared variables \texttt{[x]} and \texttt{[y]}.
We enclose accesses to shared locations into square brackets, 
in order to distinguish them from accesses to registers (local variables), 
such as \texttt{r1} and \texttt{r2} in the program above.
Threads use variables \texttt{x} or \texttt{y} to indicate 
their intention to enter the critical section.
Note the data races between writes and reads of varibles~\texttt{[x]}~and~\texttt{[y]}.

The algorithm heavily relies on the fact that both threads 
cannot simultaneously read value~\texttt{0}.
Otherwise the two threads would have been able to enter critical section simultaneously, 
thus breaking the correctness of the algorithm.
At first this assumption seems perfectly valid but let's a have a closer look.

After running this program on a multi-core system, one would expect to see 
one of the following outcomes: \texttt{\{[r$_1$=0, r$_2$=1], [r$_1$=1,r$_2$=0], [r$_1$=1,r$_2$=1]\}}.
These outcomes matche the assumptions of Dekker's algorithm.
Each one of them may be explained as a result of a sequential execution of an interleaving of threads' instructions. 
A memory model that admits only these behaviours is known under the name \emph{sequential consistency} (SC) [Lamport:TC79].

%% ANTON: If we have enough space, I'd put a figure w/ the interleavings.)
%% ANTON: IMO, we should more carefully distinguish terms "behavior" and "outcome".
%% ANTON: Also, we should state somewhere that, in the context of concurrent programs, 
%%        we use terms "semantics" and "memory model" interchangeably.

It turns out that in practice SC is too costly to be implemented.
Thus real concurrent systems have different semantics. 
For example, if one port this program to C language, compile it with the GCC compiler, 
and run on any modern CPU (including those from x86/x64, ARMv7/ARMv8, and PowerPC families)
she may also observe the outcome \texttt{[r1=0, r2=0]}.

The last non-SC behaviour is called \emph{weak},
and memory models that allows such behaviors are also called \emph{weak models}.
Weak behaviors can appear because of optimizations,
that could be performed either by the compiler or by the CPU. 
The optimizer may observe that write to \texttt{[x]} and read from \texttt{[y]}
are independent instructions and thus they may be reordered
(this optimization is perfectly valid for single-threaded programs).
After the transformation the program looks as follows

\begin{equation*}
\inarrII{
  \readInst{}{r_1}{y}  \\
  \writeInst{}{x}{1} \\
  \kw{if} {r_1 = 0} ~\{ \\
  ~~ \comment{critical section} \\
  \}
}{
  \writeInst{}{y}{1} \\
  \readInst{}{r_2}{x}  \\
  \kw{if} {r_2 = 0} ~\{ \\
  ~~ \comment{critical section} \\
  \}
}
\tag{Dekker-opt}\label{ex:Dekker-opt}
\end{equation*}

for which the outcome \texttt{[r1 = 0, r2 = 0]} can be obtained under the SC semantics.

% In order to prevent compiler and CPU from reordering of the instructions 
% and thus forbid weak behaviours and restore SC semantics
% (and consequently restore correctness the Dekker's algoritm correct)
% one has to use special primitives, called \emph{memory fences}.
% Memory fences are compiled to specal CPU instructions and additionally act as annotations to the compiler.
% However, forbiding every possible instruction reordering by putting memory fences everywhere
% has performance penalty and can slow down the program.
% Thus the programmer who want to implement concurrent algorithm 
% need to understand the memory model of the underlying system 
% and put memory fences carefully.  

Since neither the modern hardware nor programming languages 
guarantee us sequentially consistent memory model,
the main qustions then is how weak their memory models should be.
The stronger model give more guarantees and thus is simpler to reason about 
while the weaker model permits more optimizatons. 
%% It turns out that the answer depends on the type of the memory model.

Hardware and programming languages put different requirements on a memory model, 
that substantially effect its design and trade-offs.

The main requirement for the hardware memory models is that 
they should describe the behaviour of real modern CPU 
with all complex optimizations they made, like a hierarchy of memory caches, speculative executions, pipelining, etc.
Besides that the memory model should also leave some room for possible future optimizations.
Finally, it still needs to provide some reasonable guarantees for programs run on that CPU.       

%% ANTON: IMO, this section deserves some details and explanations because we aren't going to return to HW models.
%%        For example, more on future optimizations: there are behaviors allowed by models 
%%        but not observed on CPUs [Alglave-al:TOPLAS14].
%%        Maybe, here we should briefly say that HW models preserve dependencies to contrast 
%%        it to PL models (w/o OOTA details for now).)

A programming language memory model has different set of requirements.

\begin{itemize}
  \item It should permit an efficient and correct compilation scheme to the modern hardware.
  \item It should guarantee soundness of common compiler optimizations, like, for example, 
        reordering of independent instructions or common subexpression elimination.
  \item Finally, the memory still should be suitable for informal and formal 
        reasoning about the behavior of the concurrent programs.
\end{itemize}

Note that these requirements are conflicting. 
The first two pushes the model to be weaker, 
while the last one --- to be stronger. 
This conflict is the reasong why none of the existing industrial specification of memory models 
for concurrent programming languages, like C/C++ or Java, really meets all of the requirements.
A memory model that can be efficiently compiled to the hardware, admits common compiler optimizations 
and at the same time provides strong enough guarantees for informal and formal reasoning
was an open research problem for quite some time. 
Only recently a major shift has been done, but even the 
newly proposed solutions has some drawbacks, limitations, and trade-offs.    

Thus the study of weak memory models is still an active 
area of research in programming language theory,
with the new results still coming out and some open problems still unsolved.
Yet, despite the long history and recent progress made, 
there are not many materials summarizing the prior knowledge.

The goal of this paper is to give a comprehensive overview of 
the existing approaches to formal programming languages memory models,
discuss their design choices, limitations and ways to overcome them.   

The rest of the paper is organized as follows.
\todo{}.
% In section [1] we will discuss in more detail the requirements to the programming language memory models.
% On the way we will also look at specification of memory models for the C/C++ and Java languages
% and see why these models do not meet the desired requirements.
% In section [2] we will consider several proposed solutions to fix C/C++ MM. 
% Section [3] contains an overview of memory models for JavaScript/WebAssembly and OCaml languages. 
% Both of these models features some interesting properties that are currently lack in other models.
% In section [4] we compare all of the memory models presented in the paper.
% Finally, section [5] concludes with the discussion and open problems. 

% First, it should permit an efficient and correct compilation scheme to the modern hardware.
% Efficient usually means that accesses to shared memory can be compiled 
% without usage of memory fences, or with as little of them as possible. 
% Soundness means that after the compilation the program when run on hardware 
% (assuming memory model of some particular hardware) should not exhibit
% any behaviours that were not allowed by the programming language memory models. 

% Going back to the SB example, one can conclude that SC is not really satisfies this criterion. 

% Imagine if accesses to shared variables would have been compiled as plain load and store instructions of x86.
% Then after running the compiled program one would be able to observe the weak outcome \texttt{[r1 = 0, r2 = 0]}.
% This outcome is not allowed by the SC semantics and yet it can be observed.
% Thus one can conclude that this compilation scheme is unsound. 

% Alternatively, in order to preserve the SC semantics one could 
% issue \texttt{mfence} instruction after each store to shared variable.
% This compilation scheme is sound but inefficient.
% Programs compiled with such compilation scheme will run slower than 
% if they would have been compiled without memory fences.

% Besides that the programming languge memory model should guarantee soundness of common compiler optimizations,
% like, for example, reordering of independent instructions or common subexpression elimination.
% Soundness of an optimization means that after an application 
% of optimizations the program should not exibit any new behaviors.

% Considering the SB example again, it can be seen that SC is not good with this respect too.
% The allowed outcomes of the SB program are \texttt{\{[r1=0, r2=1], [r1=1,r2=0], [r1=1,r2=1]\}}.
% After reordering of independent instructions in the left thread the program looks as follows.

%% TODO: here will be a picture of SB after instruction reordering

% For this program SC model allows the following outcomes: 
% \texttt{\{[r1=0, r2=1], [r1=1,r2=0], [r1=1,r2=1], [r1=0,r2=0]\}}.
% Comparing them with the outcomes of the original program one can notice
% that there is one new outcome \texttt{[r1=0,r2=0]}.
% This an evidence that reordering of independent instructions is not sound under SC.

% Contrary to the previous requirements, the memory model still should provide some reasonable guarantees.
% (ANTON: For now, the contrast between the requirements is unclear. Maybe, at the end of the PL requirements section,
% we should mention that the first two criteria push a memory model to be weaker, whereas the third one---to be stronger.)
% (EVGENII: Currently there is a sentence about it above so perhaps it's fine now?)
% For example, it should be possible for a programmer unfamiliar with subtleties of weak memory models 
% to assume the SC model if she only uses correctly implemented synchronization primitives 
% and data-structures and has no data-races in her program.
% Guarantees of this kind are known as \emph{Data-Race Free Theorems} (DRF theorems) 
% and usually they should be provided by any sane memory model.  

% Besides that it is very desirable for a memory model to be suitable for a formal reasoning and verification.
% It implies that automated or semi-automated verification tools can be implemented 
% in order to help the developers catch bugs in their concurrent code. 

%% As we will see, this requirement is not trivially satisfiable and in fact it does not met by many existing programming language memory models.   

% It turns out that none of the existing industrial specification of memory models 
% for concurrent programming languages, like C/C++ or Java, really meets all of the requirements.
% A memory model that can be efficiently compiled to the hardware, admits common compiler optimizations 
% and at the same time provides strong enough guarantees for informal and formal reasoning
% was an open research problem for quite some time. 
% Only recently a major shift has been done, but even the 
% newly proposed solutions has some drawbacks, limitations, and trade-offs.    

%% Batty:ESOP15, PhD thesis

\section{Related Work}

%% move to introduction


%% cite previous surveys

It was early on realized that sequential consistency memory model is too costly to be implemented. 
The pioneering work on weak memory models started with the attempt to 
invent a more optimization-friendly memory model 
for shared memory multiprocessors~\cite{Adve:PhD93, Adve:Comp96}.
Since then a large amount of effots were put to formally specify weak memory models of various 
hardware architectures~\cite{Chong-ASPLOS08, Alglave-DAMP09, Sewell-al:CACM10, Sarkar-al:PLDI11, Flur-al:POPL16}.
The work~\cite{Alglave-al:TOPLAS14} summarized different studies in the area 
of hardware weak memory models and proposed a general 
framework to specify, test and verify them.

A lot of work has also been done in the area of programming language weak memory models.
Memory models have been proposed for the languages
Java~\cite{Manson-al:POPL05}, C/C++~\cite{Boehm-Adve:PLDI08, Batty-al:POPL11}, 
OpenCL~\cite{Batty-el:POPL16}, LLVM~\cite{Chakraborty-Vafeiadis:CGO17}, 
OCaml~\cite{Dolan-al:PLDI18}, JavaScript/WebAssembly~\cite{Watt-el:PLDI2020}.
%% TODO: recent works on Java opaque accesses (?)
It was then shown that some compiler optimizations are unsound 
for Java model~\cite{Sevcik-Aspinall:ECOOP08}, that is the model is too strong.
As for C/C++ model it was observed that the model both is too strong 
to permit some compiler optimizations~\cite{Vafeiadis-al:POPL15} and too weak to 
be suitable for any kind of formal or informal reasoning~\cite{Boehm-Demsky:MSPC14}. 
Memory models of OpenCL and LLVM follow closely the C/C++ model
and thus inherent some of its problems.
OCaml and JavaScript have chosen consciously to strengthening their memory models
to overcome problems specific to C/C++ and thus sacrifice performance. 

The problem of C/C++ model being overly weak \app{Some details} has 
been formally stated and studied in~\cite{Batty-al:ESOP15}.
Many of the subsequent works were dedicated 
to strengthen the model ``just enough'' to outlaw undesired behaviours
and yet support efficient compilation and 
common optimizations~\cite{Jeffrey-Riely:LICS16, PichonPharabod-Sewell:POPL16, 
Podkopaev-al:CoRR16, Kang-al:POPL17, Chakraborty-Vafeiadis:POPL19, Lee-el:PLDI20}. 

With the large number of new memory models for programming languages
proposed recently there is a need in a detailed survey on recent trends in this field.
The aim of this paper is to provide such survey and to systemize the prior work.
 
% Work on the C/C++ memory model has started from the observation that multithreading cannot
% be implemented as a library~\cite{} (e.g. \texttt{pthreads} library)
% and that the language standard requires a clear and concise specification of the concurrency semantics.

\section{Methodology}

The purpose of our study is to compare weak memory models for programming languages.
In particular, with respect to each model we want to answer the following questions.

% In particular, we want to compare them with respect to several criterias
% that can be partioned into three classes.

\begin{itemize}
  
  \item Can the memory model be efficiently implemented on modern hardware? 
    In other words, is the compilation scheme for a model sound and efficient?
    If the compilation scheme is not optimal, then how large is induced performance overhead?

  \item What compiler optimizations are correct in the model? What are not? 
    How large is performance impact for the generated code in case when 
    some optimizations are disabled due to unsoundness.

  \item What is the subjective complexity of the model?
    How easy it is to reason about the behavior of the model for non-experts?
    Is the model suitable for formal verification?
  
\end{itemize}

For our research we have chosen a number of memory models 
that we previously published 
%% either as a part of specifications of corresponded programming languages or 
in form of research papers in peer-reviewed journals or conference proceedings. 
Below we explain the motivation behind our choice of each particular memory model.  

%% Class of memory models (think how to introduce that)

%% We consider only "C/C++ style" MMs

%% General purpose not GPU

We included \textbf{sequential consistency} as a ``baseline'' memory model. 
It is simple, does not permit any counter-intuitive behaviors,
and has clear formal specification. 

We consider \textbf{Java} memory model (\textbf{JMM})~\cite{Manson-al:POPL05}
and \textbf{C/C++} memory model (\textbf{CMM})~\cite{Boehm-Adve:PLDI08, Batty-al:POPL11}
because of their significance and impact on software engineering industry.
On the contrary, we exclude OpenCL~\cite{Batty-el:POPL16}
\app{We could say that we consider MMs only for general-purpose PLs. OpenCL is for GPUs.}
and LLVM~\cite{Chakraborty-Vafeiadis:CGO17}
\app{But we do consider Weakestmo, which is the extension of~\cite{Chakraborty-Vafeiadis:CGO17}.
It is strange.}
models because they are based on C/C++ model and have no significant distinctions
with respect to our criteria.

Next, we consider a number of proposed memory models 
that aim to repair C/C++ model, namely 
\textbf{Repaired C11} (\textbf{RC11})~\cite{Lahav-al:PLDI17}, 
\textbf{Promising}~\cite{Kang-al:POPL17, Lee-el:PLDI20}, 
\textbf{Weakest}~\cite{Chakraborty-Vafeiadis:POPL19}, 
\textbf{Relaxed Modular Dependencies} (\textbf{RMD})~\cite{Paviotti-el:ESOP20}.

%% RMW --> MRD 

%% TODO: explain why we excluded~\cite{Jeffrey-Riely:LICS16, PichonPharabod-Sewell:POPL16}.
%% Jeffrey-Riely:LICS16 --> MRD
%% PichonPharabod --- mistakes, incomplete, (?)

Finally, we also included memory models of \textbf{OCaml}~\cite{Dolan-al:PLDI18}
and \textbf{JavaScript/WebAssembly}~\cite{Watt-el:PLDI2020}.
These models are of some interest becuase 
they have some distinctive properties
that other models currently lacking.

\app{Mentioned that there are PL MMs, which have different to Java/C++ style of
  atomic interface, \emph{i.e.} \cite{Crary-Sullivan:POPL15}.
}

\section{Requirements to Programming Language Weak Memory Model}

In this section we will have a closer look into the requirements 
that a programming language memory model should satisfy, 
namely the existence of sound and efficient compilation scheme, 
soundness of common optimizations, and guarantees for formal and informal reasoning.  
Taking as an examples three memory models: 
sequential consistency, Java memory model and C/C++ memory model
we will see that each of them fails at least in one aspect.
%% EVGENII: also cite corresponding java and c/c++ specs?

\subsection{Memory models under consideration}

We chose to demonstrate the requirements to models on the example of SC, CMM and JMM for reason.
Again, SC was picked as a ``baseline''.
The other two models, Java and C/C++, was chosen because 
(1) they were the first formally specified memory models of industrial programming languages, and
(2) they are significantly differ in their design and goals.

\subsubsection{C/C++ Memory Model}

Memory model of the C/C++ follows the design principles of the language itself.

C and C++ languages positions themselves as low-level programming languages
that provide zero-cost abstractions that generally do not put any performance penalties. 
In other words the abstraction that these languages provide 
should be compiled into efficient assembly code,
and leave the room for the aggressive optimizations.

The efficiency of the compiled code however comes with a certain cost.
The programmer should strictly obey the rules and conventions
established by the language's specification, 
otherwise program is said to have \emph{undefined behavior} (UB for short)

With respect to the memory model, the above means that C/C++ compiler should
compile accesses to shared variables as plain memory accesses of the CPU,
and provide to the programmer low-level syncronization primitives
that can be mapped directly to CPU instructions.
Besides that, the compiler should be able to perform 
as many optimizations as possible to the code containing shared accesses.
As we will see, not all of the optimizations that are sound 
for a single thread program reamins sound for concurrent programs that contain data races. 
%% TODO: give some example? reordering of reads to the same location, as Anton suggested? 

For these reasons C/C++ distinguish two kind of memory accesses.
Non-atomic accesses are can be used to perform read or write to memory that 
is owned exclusively by one thread at the time of the access.
Data-races on non-atomic accesses lead to undefined behavior for the whole program
(so called \emph{catch-fire} semantics).
In contrast, atomic accesses can be used to access memory that can be shared between different threads. 
The results of data-races on these accesses are specified by the language and do not lead to undefined behavior.
The consequence is that some of the compiler optimization are not applicable to atomic accesses.
In addition to two kinds of memory accesses C/C++ also provide fences ---
low-level synchronization primitives similar to CPUs fence instructions.

\subsubsection{Java Memory Model}

The Java language makes different design choices and has different tradeoffs comparing to C/C++.
Unlike the later languages, Java provides safety and security guarantees
which are enforced both at compile time and at runtime.  
Thus Java language specification cannot tolerate undefined behaviors.
Despite that the Java compilers still make a lot of effort 
to provide good performance of the compiled code.

Consequently, Java memory model should follow this design 
and do not break any of the language's guarantees
while still admit fairly efficient compilation scheme
and allow as many optimizations as possible.

\subsection{Sound and efficient compilation scheme}

Having a short description of the memory models 
together with their design goals we are ready to proceed 
and consider whether these models satisfy the desired requirements.
We are going to start with compilation schemes.

As we have seen, the memory models of modern CPUs 
(those based on x86, ARMv8 and POWER architecture)
are weak and allow non sequentially consistent behaviors.
This is a result of various optimization implemented in hardware,
including instruction pipelines, speculative out of order executions, 
hierarchy of caches with complex coherence protocols, and others.

If the memory model wants to provide stronger guarantees 
than the CPU does (as for example sequentially consistent model)
it should somehow prevent the out of order executions.
In general, there are two ways to achieve that. 

First, as we have already discussed, special fence instructions,
provided by the CPU (such as \texttt{mfence} on x86) can be used.
These instructions usually flush caches, prevent speculative executions
and perform any other actions required by the hardware architecture
to forbid various weak behaviours.

Second, all modern hardware architectures do not reorder instructions 
if there are \emph{syntactic dependencies} between them. 
For example, the load instruction cannot be moved below 
the store instruction if there is conditional jump instruction between them.
The compiler can utilize this and prevent 
the reordering of the load instruction below subsequent stores
by emiting a usuless conditional jump instruction that would jump 
to the same label no matter what is the result of condition evaluation.
Dependencies of such kind can be computed following the 
syntax of the program (hence the name) as opposed 
to \emph{semantic dependencies} 
(we will see the difference between the two later).

Now that we have CPU fences and syntactic dependencies in our service
let's have a look at how they are used in real compilation schemes.

\subsubsection{Compiling SC}

Sequential consistency model is very expensive to implement in hardware. 
For this reasons all modern hardware architectures (including rather strong x86) do not provide it. 
We have seen this on the examples of Dekker lock and SB programs in \ref{introduction}.

In order to restore the sequential consistency on x86 one has to 
insert \texttt{mfence} instruction after each write.
On ARMv7 and POWER one need to insert full memory fence
(\texttt{dmb} and \texttt{sync} on ARMv7/POWER correspondingly)
before each write,
emit same full fence before each read, and also
add a syntactic dependency with special instruction fence 
(\texttt{isb} and \texttt{isync} on ARMv7/POWER correspondingly)
after the read.
Newer ARMv8 chips allows simpler solution, 
one just need to compile accesses to special 
load/store instruction to restore SC semantics
(\texttt{ldar} and \texttt{stlr}).
The table summarizes the resulting compilation mappings.

%% TODO: Here will be the table with compilation mappings

The natural question to ask is how much of the performance penalties
these compilation mappings induce compared to compiling all accesses as plain ones
without any fences or artificial syntactic dependencies.

%% TODO: cite some paper, present table with measurements etc. 

Thus one can see that enforcing sequential consistency on modern hardware is costly.

\subsubsection{Compiling C/C++}

\subsubsection{Compiling Java}

%% TODO: compiler optimizations --> program transformations (?)

\subsection{Soundness of compiler optimizations}

\subsubsection{Soundness of optimizations in SC}

\subsubsection{Soundness of optimizations in C/C++}

\subsubsection{Soundness of optimizations in Java}

\subsection{Reasoning}

\subsubsection{DRF Theorems}

\subsubsection{Model checking}

\section{No-Thin-Air Memory Models}

\section{Other Models and Features}

\input{comparison.tex}

\section{Discussion and Open Problems}

\bibliography{main} 
\bibliographystyle{ieeetr}

\end{document}
