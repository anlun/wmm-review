\documentclass[a4paper,twoside,11pt]{article}
\usepackage[cp1251]{inputenc}
\usepackage[english,russian]{babel}
\usepackage{fancyhdr}
\usepackage{newprog1e}
\usepackage{amsfonts,amsmath,amssymb,amsthm}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{xcolor}
\usepackage{tikz}
\usepackage{cleveref}
\usepackage{sansmath}
\usepackage{xspace}

\tolerance=1000

\newcommand{\defi}{\stackrel{\mathrm{def}}{=}}

\numberwithin{equation}{section}
\newtheorem{theorem}{Theorem}

\newtheorem{definition}{Definition}

\journalnumber{2}
\curyear{2020}
\authorlist{}
\titlehead{}
\headerdef

\udk{004.421.6}
%92+004.94}
\rubrika{}
\dateinput{01.12.2020}

\rusabstr{}

\author{Anonymous Authors}
\title{A Survey of Programming Language Memory Models}
%\thanks{~}

\date{}

\input{defs.tex}

\begin{document}

\maketitle
%\tableofcontents

\begin{abstract}
\end{abstract}

\section{Introduction}

A main challenge in concurrent programming is 
to establish a proper synchronization between threads executed in parallel.     
Usually it is done with the help of synchronization primitives
provided by the programming language or libraries,
for example locks, barriers, channels \etc
Sometimes, however, the usage of these primitives
is not possible or undesirable. 
Examples of such cases are the implementation 
of synchronization primitive themselves
or lock-free data structures.
In these cases one has to resort to 
lower-level programming discipline and 
use just the mutable shared variables. 
At this point things get complicated.

%The memory model defines which values reads of shared variables can observe at each point of execution. 
%In other words, it defines the semantics of concurrent program.

Let us consider a concrete example.
Here is a simplified version of Dekker's algorithm for mutual exclusion.

\begin{equation*}
\inarrII{
  \writeInst{}{x}{1} \\
  \readInst{}{r_1}{y}  \\
  \kw{if} {r_1 = 0} ~\{ \\
  ~~ \comment{critical section} \\
  \}
}{
  \writeInst{}{y}{1} \\
  \readInst{}{r_2}{x}  \\
  \kw{if} {r_2 = 0} ~\{ \\
  ~~ \comment{critical section} \\
  \}
}
\tag{Dekker}\label{ex:Dekker}
\end{equation*}

In this program there are two threads that compete to enter critical section.
In order to indicate their intention threads set 
variables \texttt{[x]} and \texttt{[y]} correspondinly
\footnote{We enclose names of shared variables into square brackets
(\ie \texttt{[x]}, \texttt{[y]}), in order to distinguish them 
from local registers (\ie \texttt{r1} and \texttt{r2}).}.
The one who manages to set the variable first wins.
The algorithm relies on the fact that both threads 
cannot simultaneously read value~\texttt{0}.
Otherwise the two threads would have been able 
to enter critical section simultaneously, 
thus breaking the correctness of the algorithm.

Indeed after running this program on a multi-core system, one would expect to see 
one of the following outcomes: \texttt{\{[r$_1$=0, r$_2$=1], [r$_1$=1,r$_2$=0], [r$_1$=1,r$_2$=1]\}}.
These outcomes are said to be \emph{sequential consistent}~\cite{Lamport:TC79}
because they can be obtained by the sequential execution 
of some interleaving of threads' instructions. 

%A memory model that admits only these behaviours is known under the name \emph{sequential consistency} (SC) [Lamport:TC79].

%% ANTON: If we have enough space, I'd put a figure w/ the interleavings.)
%% ANTON: IMO, we should more carefully distinguish terms "behavior" and "outcome".
%% ANTON: Also, we should state somewhere that, in the context of concurrent programs, 
%%        we use terms "semantics" and "memory model" interchangeably.

However, the real concurrent systems can have different semantics. 
For example, if one port this program to C language, compile it with the GCC compiler, 
and run on processor from x86/x64 family
she may also observe yet another outcome \texttt{[r1=0, r2=0]},
which is called \emph{weak}.

Weak outcomes can appear because of optimizations,
that could be performed either by the compiler or by the CPU. 
For example, in the program above, 
the optimizer may observe that write 
to \texttt{[x]} and read from \texttt{[y]}
are independent instructions and thus they can be reordered
(this optimization is perfectly valid for single-threaded programs).
For the optimized program the outcome \texttt{[r1 = 0, r2 = 0]}
is sequentially consistent.

The exact set of allowed outcomes for a given program 
is defined by the \emph{memory model}.
The memory model that permits only sequentially consistent outcomes 
is called correspondingly \emph{sequential consistency} (SC).
Memory models that admit weak, that is non sequentially consistent, 
outcomes form a large class of so-called \emph{weak memory models}.

Neither the modern hardware nor programming languages 
guarantee us sequentially consistent memory model,
because it forbids many important optimizations.
The main question then is how weak their memory models should be.
The stronger model give more guarantees 
and thus is simpler to reason about 
while the weaker model permits more 
useful optimizatons.

It turns out that this question, 
at least in the context of programming language 
memory models, is quite challenging. 
Thus over the last two decades many memory models have been proposed~\cite{
Manson-al:POPL05, Batty-al:POPL11, Dolan-al:PLDI18, 
Watt-el:OOPSLA19, Watt-el:PLDI2020,
Jeffrey-Riely:LICS16, PichonPharabod-Sewell:POPL16, 
Kang-al:POPL17, Chakraborty-Vafeiadis:POPL19, 
Paviotti-el:ESOP20, Lee-el:PLDI20}. 
These memory models have different design goals, trade-offs, and limitations.
Yet for the people unfamiliar with all the subtelties 
of weak memory models it can be hard to navigate in this large zoo.
Despite the long history of the field and recent progress made, 
there is no single source that would summare the prior knowledge
and give comprehensive comparison of different memory models
of programming languages.

The aim of this paper is to close this gap.
We provide an overview of the existing approaches to 
formal programming languages memory models,
discuss their design choices, trade-offs and limitations.
Besides that we compare the existing memory models 
in terms of how many CPU and compiler optimizations 
they permit and what guarantees for formal reasoning they provide.
As a result of our study we present the table with a summary of this comparison.

We believe our work will help the developers,
who are working on implementation of synchronization primitives
or lock-free data structures, and thus have to understand 
the subtelties of weak memory models.
We also think it would be a great help to 
programmers who want to build new 
programming languages, compilers or virtual machines,
and thus have to choose the memory model of their system. 

The rest of the paper is organized as follows.
\todo{}.
% In section [1] we will discuss in more detail the requirements to the programming language memory models.
% On the way we will also look at specification of memory models for the C/C++ and Java languages
% and see why these models do not meet the desired requirements.
% In section [2] we will consider several proposed solutions to fix C/C++ MM. 
% Section [3] contains an overview of memory models for JavaScript/WebAssembly and OCaml languages. 
% Both of these models features some interesting properties that are currently lack in other models.
% In section [4] we compare all of the memory models presented in the paper.
% Finally, section [5] concludes with the discussion and open problems. 

\input{related-work.tex}
\input{methodology.tex}

\section{Requirements to Programming Language Weak Memory Model}

In this section we will have a closer look into the requirements 
that a programming language memory model should satisfy, 
namely the existence of sound and efficient compilation scheme, 
soundness of common optimizations, and guarantees for formal and informal reasoning.  
Taking as an examples three memory models: 
sequential consistency, Java memory model and C/C++ memory model
we will see that each of them fails at least in one aspect.
%% EVGENII: also cite corresponding java and c/c++ specs?

\subsection{Memory models under consideration}

We chose to demonstrate the requirements to models on the example of SC, CMM and JMM for reason.
Again, SC was picked as a ``baseline''.
The other two models, Java and C/C++, was chosen because 
(1) they were the first formally specified memory models of industrial programming languages, and
(2) they are significantly differ in their design and goals.

\subsubsection{C/C++ Memory Model}

Memory model of the C/C++ follows the design principles of the language itself.

C and C++ languages positions themselves as low-level programming languages
that provide zero-cost abstractions that generally do not put any performance penalties. 
In other words the abstraction that these languages provide 
should be compiled into efficient assembly code,
and leave the room for the aggressive optimizations.

The efficiency of the compiled code however comes with a certain cost.
The programmer should strictly obey the rules and conventions
established by the language's specification, 
otherwise program is said to have \emph{undefined behavior} (UB for short)

With respect to the memory model, the above means that C/C++ compiler should
compile accesses to shared variables as plain memory accesses of the CPU,
and provide to the programmer low-level syncronization primitives
that can be mapped directly to CPU instructions.
Besides that, the compiler should be able to perform 
as many optimizations as possible to the code containing shared accesses.
As we will see, not all of the optimizations that are sound 
for a single thread program reamins sound for concurrent programs that contain data races. 
%% TODO: give some example? reordering of reads to the same location, as Anton suggested? 

For these reasons C/C++ distinguish two kind of memory accesses.
Non-atomic accesses are can be used to perform read or write to memory that 
is owned exclusively by one thread at the time of the access.
Data-races on non-atomic accesses lead to undefined behavior for the whole program
(so called \emph{catch-fire} semantics).
In contrast, atomic accesses can be used to access memory that can be shared between different threads. 
The results of data-races on these accesses are specified by the language and do not lead to undefined behavior.
The consequence is that some of the compiler optimization are not applicable to atomic accesses.
In addition to two kinds of memory accesses C/C++ also provide fences ---
low-level synchronization primitives similar to CPUs fence instructions.

\subsubsection{Java Memory Model}

The Java language makes different design choices and has different tradeoffs comparing to C/C++.
Unlike the later languages, Java provides safety and security guarantees
which are enforced both at compile time and at runtime.  
Thus Java language specification cannot tolerate undefined behaviors.
Despite that the Java compilers still make a lot of effort 
to provide good performance of the compiled code.

Consequently, Java memory model should follow this design 
and do not break any of the language's guarantees
while still admit fairly efficient compilation scheme
and allow as many optimizations as possible.

\subsection{Sound and efficient compilation scheme}

Having a short description of the memory models 
together with their design goals we are ready to proceed 
and consider whether these models satisfy the desired requirements.
We are going to start with compilation schemes.

As we have seen, the memory models of modern CPUs 
(those based on x86, ARMv8 and POWER architecture)
are weak and allow non sequentially consistent behaviors.
This is a result of various optimization implemented in hardware,
including instruction pipelines, speculative out of order executions, 
hierarchy of caches with complex coherence protocols, and others.

If the memory model wants to provide stronger guarantees 
than the CPU does (as for example sequentially consistent model)
it should somehow prevent the out of order executions.
In general, there are two ways to achieve that. 

First, as we have already discussed, special fence instructions,
provided by the CPU (such as \texttt{mfence} on x86) can be used.
These instructions usually flush caches, prevent speculative executions
and perform any other actions required by the hardware architecture
to forbid various weak behaviours.

Second, all modern hardware architectures do not reorder instructions 
if there are \emph{syntactic dependencies} between them. 
For example, the load instruction cannot be moved below 
the store instruction if there is conditional jump instruction between them.
The compiler can utilize this and prevent 
the reordering of the load instruction below subsequent stores
by emiting a usuless conditional jump instruction that would jump 
to the same label no matter what is the result of condition evaluation.
Dependencies of such kind can be computed following the 
syntax of the program (hence the name) as opposed 
to \emph{semantic dependencies} 
(we will see the difference between the two later).

Now that we have CPU fences and syntactic dependencies in our service
let's have a look at how they are used in real compilation schemes.

\subsubsection{Compiling SC}

Sequential consistency model is very expensive to implement in hardware. 
For this reasons all modern hardware architectures (including rather strong x86) do not provide it. 
We have seen this on the examples of Dekker lock and SB programs in \ref{introduction}.

In order to restore the sequential consistency on x86 one has to 
insert \texttt{mfence} instruction after each write.
On ARMv7 and POWER one need to insert full memory fence
(\texttt{dmb} and \texttt{sync} on ARMv7/POWER correspondingly)
before each write,
emit same full fence before each read, and also
add a syntactic dependency with special instruction fence 
(\texttt{isb} and \texttt{isync} on ARMv7/POWER correspondingly)
after the read.
Newer ARMv8 chips allows simpler solution, 
one just need to compile accesses to special 
load/store instruction to restore SC semantics
(\texttt{ldar} and \texttt{stlr}).
The table summarizes the resulting compilation mappings.

%% TODO: Here will be the table with compilation mappings

The natural question to ask is how much of the performance penalties
these compilation mappings induce compared to compiling all accesses as plain ones
without any fences or artificial syntactic dependencies.

%% TODO: cite some paper, present table with measurements etc. 

Thus one can see that enforcing sequential consistency on modern hardware is costly.

\subsubsection{Compiling C/C++}

\subsubsection{Compiling Java}

%% TODO: compiler optimizations --> program transformations (?)

\subsection{Soundness of compiler optimizations}

\subsubsection{Soundness of optimizations in SC}

\subsubsection{Soundness of optimizations in C/C++}

\subsubsection{Soundness of optimizations in Java}

\subsection{Reasoning}

\subsubsection{DRF Theorems}

\subsubsection{Model checking}

\section{No-Thin-Air Memory Models}

\section{Other Models and Features}

\input{comparison.tex}

\section{Discussion and Open Problems}

\bibliography{main} 
\bibliographystyle{ieeetr}

\end{document}
