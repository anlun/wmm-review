\section{Introduction}

A main challenge in concurrent programming is 
to establish a proper synchronization between threads executed in parallel.     
Usually it is done with the help of synchronization primitives
provided by the programming language or libraries,
for example locks, barriers, channels \etc
Sometimes, however, the usage of these primitives
is not possible or undesirable. 
Examples of such cases are the implementation 
of synchronization primitive themselves
or lock-free data structures.
In these cases one has to resort to 
lower-level programming discipline and 
use just the mutable shared variables. 
At this point things get complicated.

%The memory model defines which values reads of shared variables can observe at each point of execution. 
%In other words, it defines the semantics of concurrent program.

Let us consider a concrete example.
Here is a simplified version of Dekker's algorithm for mutual exclusion.

\begin{equation*}
\inarrII{
  \writeInst{}{x}{1} \\
  \readInst{}{r_1}{y}  \\
  \kw{if} {r_1 = 0} ~\{ \\
  ~~ \comment{critical section} \\
  \}
}{
  \writeInst{}{y}{1} \\
  \readInst{}{r_2}{x}  \\
  \kw{if} {r_2 = 0} ~\{ \\
  ~~ \comment{critical section} \\
  \}
}
\tag{Dekker}\label{ex:Dekker}
\end{equation*}

In this program, there are two threads that compete to enter critical section.
In order to indicate their intention threads set 
variables $x$ and $y$ correspondingly.%
\footnote{We enclose names of shared variables into square brackets
(\ie $x$, $y$), in order to distinguish them 
from local registers (\ie $r_1$ and $r_2$).}
The one who manages to set the variable first wins.
The algorithm relies on the fact that both threads cannot read value~\texttt{0}.
Otherwise, the two threads would have been able 
to enter critical section simultaneously, 
thus breaking the correctness of the algorithm.

Indeed, after running this program on a multi-core system, one would expect to see 
one of the following outcomes: $[r_1=0, r_2=1]$, $[r_1=1,r_2=0]$, and $[r_1=1,r_2=1]$.
These outcomes are \emph{sequential consistent}~\cite{Lamport:TC79} meaning
that they may be obtained by a sequential execution 
of some interleaving of threads' instructions. 

%A memory model that admits only these behaviours is known under the name \emph{sequential consistency} (SC) [Lamport:TC79].

%% ANTON: If we have enough space, I'd put a figure w/ the interleavings.)
%% ANTON: IMO, we should more carefully distinguish terms "behavior" and "outcome".
%% ANTON: Also, we should state somewhere that, in the context of concurrent programs, 
%%        we use terms "semantics" and "memory model" interchangeably.

However, not all behaviors which are observable on real concurrent systems are sequentially consistent. 
For example, if one ports the \ref{ex:Dekker} program to the C language, compile it with the GCC compiler, 
and run on a processor from the x86/x64 family,
she may observe yet another outcome $[r_1=0, r_2=0]$,
which is called \emph{weak}, \ie not sequentially consistent.

Weak outcomes appear because of compiler and CPU optimizations.
For example, in the \ref{ex:Dekker} program,
the optimizer may observe that the store to $x$ and the load from $y$ in the left thread
are independent instructions and thus they can be reordered
(this optimization is perfectly valid for single-threaded programs).
For the optimized program, the outcome $[r_1=0, r_2=0]$
is sequentially consistent.

The exact set of allowed outcomes for a given program 
is defined by a semantics of a concurrent system, or a \emph{memory model}.
The memory model permitting only sequentially consistent outcomes 
is called \emph{sequential consistency} (SC).
Memory models admitting \emph{weak}, \ie non sequentially consistent, behaviors 
are called \emph{weak memory models}.

Neither modern hardware nor programming languages 
guarantee sequential consistency since SC forbids many important optimizations.
The main question then is how \emph{weak} their memory models should be,
\ie how big is a set of allowed weak behaviors for a given program.
A stronger model allows less behaviors, thus giving more guarantees to a programmer
and simplifying reasoning about programs, but a weaker model permits more optimizations,
thus allowing a compiler to produce more efficient code and a CPU to execute the code faster.

It turns out that this question, 
at least in the context of programming language 
memory models, is quite challenging. 
Thus over the last two decades many memory models have been proposed~\cite{
Manson-al:POPL05, Batty-al:POPL11, Batty-el:POPL16, 
Dolan-al:PLDI18, Watt-el:OOPSLA19, Watt-el:PLDI2020, 
Jeffrey-Riely:LICS16, PichonPharabod-Sewell:POPL16, 
Podkopaev-al:CoRR16, Kang-al:POPL17, Chakraborty-Vafeiadis:POPL19, 
Paviotti-el:ESOP20, Lee-el:PLDI20}. 
These memory models have different design goals, trade-offs, and limitations.
For the people unfamiliar with all the subtleties 
of weak memory models, it can be hard to navigate in this large zoo.
Despite the long history of the field and recent progress made, 
there is no single source that would summare the prior knowledge
and give comprehensive comparison of different memory models
of programming languages.

The aim of this paper is to close this gap.
We provide an overview of the existing approaches to 
formal programming languages memory models,
discuss their design choices, trade-offs and limitations.
Besides that, we compare the existing memory models 
in terms of how many CPU and compiler optimizations 
they permit and what guarantees for formal reasoning they provide.
As a result of our study, we present a summary of this comparison.

We believe our work will help the developers,
who are working on implementation of synchronization primitives
or lock-free data structures, and thus have to understand 
the subtleties of weak memory models.
We also think it would be a great help to 
programmers who want to build new 
programming languages, compilers or virtual machines,
and thus have to choose the memory model of their system. 

The rest of the paper is organized as follows.
\todo{}.
% In section [1] we will discuss in more detail the requirements to the programming language memory models.
% On the way we will also look at specification of memory models for the C/C++ and Java languages
% and see why these models do not meet the desired requirements.
% In section [2] we will consider several proposed solutions to fix C/C++ MM. 
% Section [3] contains an overview of memory models for JavaScript/WebAssembly and OCaml languages. 
% Both of these models features some interesting properties that are currently lack in other models.
% In section [4] we compare all of the memory models presented in the paper.
% Finally, section [5] concludes with the discussion and open problems. 
